{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict and Extract Features with Pre-trained Models\n",
    "\n",
    "This tutorial will work through how to use pre-trained models for predicting and feature extraction.\n",
    "\n",
    "## Download pre-trained models\n",
    "\n",
    "A model often contains two parts, the `.json` file specifying the neural network structure, and the `.params` file containing the binary parameters. The name convention is `name-symbol.json` and `name-epoch.params`, where `name` is the model name, and `epoch` is the epoch number. \n",
    "\n",
    "\n",
    "Here we download a pre-trained Resnet 50-layer model on Imagenet. Other models are available at http://data.mxnet.io/models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, urllib\n",
    "def download(url):\n",
    "    filename = url.split(\"/\")[-1]\n",
    "    if not os.path.exists(filename):\n",
    "        urllib.urlretrieve(url, filename)\n",
    "def get_model(prefix, epoch):\n",
    "    download(prefix+'-symbol.json')\n",
    "    download(prefix+'-%04d.params' % (epoch,))\n",
    "\n",
    "get_model('http://data.mxnet.io/models/imagenet/resnet/50-layers/resnet-50', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "\n",
    "We first load the model into memory with `load_checkpoint`. It returns the symbol (see [symbol.ipynb](../basic/symbol.ipynb)) definition of the neural network, and parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "sym, arg_params, aux_params = mx.model.load_checkpoint('resnet-50', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the neural network by `mx.viz.plot_network`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Draw network requires graphviz library",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-4badfe24651c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mviz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msym\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Anaconda2\\lib\\site-packages\\mxnet-0.7.0-py2.7.egg\\mxnet\\visualization.pyc\u001b[0m in \u001b[0;36mplot_network\u001b[0;34m(symbol, title, shape, node_attrs)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mgraphviz\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDigraph\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Draw network requires graphviz library\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msymbol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSymbol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"symbol must be Symbol\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Draw network requires graphviz library"
     ]
    }
   ],
   "source": [
    "mx.viz.plot_network(sym)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both argument parameters and auxiliary parameters (e.g mean/std in batch normalization layer) are stored as a dictionary of string name and ndarray value (see [ndarray.ipynb](../basic/ndarray.ipynb)). The arguments contain \n",
    "consist of weight and bias. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bn0_beta': <mxnet.ndarray.NDArray at 0x81a5f98>,\n",
       " 'bn0_gamma': <mxnet.ndarray.NDArray at 0x8194d68>,\n",
       " 'bn1_beta': <mxnet.ndarray.NDArray at 0x81a5400>,\n",
       " 'bn1_gamma': <mxnet.ndarray.NDArray at 0x81a5978>,\n",
       " 'bn_data_beta': <mxnet.ndarray.NDArray at 0x8185400>,\n",
       " 'bn_data_gamma': <mxnet.ndarray.NDArray at 0x819cd68>,\n",
       " 'conv0_weight': <mxnet.ndarray.NDArray at 0x8194f60>,\n",
       " 'fc1_bias': <mxnet.ndarray.NDArray at 0x819ce48>,\n",
       " 'fc1_weight': <mxnet.ndarray.NDArray at 0x81a5eb8>,\n",
       " 'stage1_unit1_bn1_beta': <mxnet.ndarray.NDArray at 0x81a5160>,\n",
       " 'stage1_unit1_bn1_gamma': <mxnet.ndarray.NDArray at 0x819c7f0>,\n",
       " 'stage1_unit1_bn2_beta': <mxnet.ndarray.NDArray at 0x81a5080>,\n",
       " 'stage1_unit1_bn2_gamma': <mxnet.ndarray.NDArray at 0x81949e8>,\n",
       " 'stage1_unit1_bn3_beta': <mxnet.ndarray.NDArray at 0x819cb38>,\n",
       " 'stage1_unit1_bn3_gamma': <mxnet.ndarray.NDArray at 0x81a50b8>,\n",
       " 'stage1_unit1_conv1_weight': <mxnet.ndarray.NDArray at 0x8194710>,\n",
       " 'stage1_unit1_conv2_weight': <mxnet.ndarray.NDArray at 0x8194518>,\n",
       " 'stage1_unit1_conv3_weight': <mxnet.ndarray.NDArray at 0x283dda0>,\n",
       " 'stage1_unit1_sc_weight': <mxnet.ndarray.NDArray at 0x8185d68>,\n",
       " 'stage1_unit2_bn1_beta': <mxnet.ndarray.NDArray at 0x81af198>,\n",
       " 'stage1_unit2_bn1_gamma': <mxnet.ndarray.NDArray at 0x81a5940>,\n",
       " 'stage1_unit2_bn2_beta': <mxnet.ndarray.NDArray at 0x819cac8>,\n",
       " 'stage1_unit2_bn2_gamma': <mxnet.ndarray.NDArray at 0x81a5588>,\n",
       " 'stage1_unit2_bn3_beta': <mxnet.ndarray.NDArray at 0x819cef0>,\n",
       " 'stage1_unit2_bn3_gamma': <mxnet.ndarray.NDArray at 0x819c8d0>,\n",
       " 'stage1_unit2_conv1_weight': <mxnet.ndarray.NDArray at 0x819c2e8>,\n",
       " 'stage1_unit2_conv2_weight': <mxnet.ndarray.NDArray at 0x8194208>,\n",
       " 'stage1_unit2_conv3_weight': <mxnet.ndarray.NDArray at 0x81af278>,\n",
       " 'stage1_unit3_bn1_beta': <mxnet.ndarray.NDArray at 0x81a5e10>,\n",
       " 'stage1_unit3_bn1_gamma': <mxnet.ndarray.NDArray at 0x81af080>,\n",
       " 'stage1_unit3_bn2_beta': <mxnet.ndarray.NDArray at 0x8194780>,\n",
       " 'stage1_unit3_bn2_gamma': <mxnet.ndarray.NDArray at 0x8194048>,\n",
       " 'stage1_unit3_bn3_beta': <mxnet.ndarray.NDArray at 0x8185f98>,\n",
       " 'stage1_unit3_bn3_gamma': <mxnet.ndarray.NDArray at 0x81a54e0>,\n",
       " 'stage1_unit3_conv1_weight': <mxnet.ndarray.NDArray at 0x81a5ef0>,\n",
       " 'stage1_unit3_conv2_weight': <mxnet.ndarray.NDArray at 0x819c588>,\n",
       " 'stage1_unit3_conv3_weight': <mxnet.ndarray.NDArray at 0x283d358>,\n",
       " 'stage2_unit1_bn1_beta': <mxnet.ndarray.NDArray at 0x81a5fd0>,\n",
       " 'stage2_unit1_bn1_gamma': <mxnet.ndarray.NDArray at 0x8194470>,\n",
       " 'stage2_unit1_bn2_beta': <mxnet.ndarray.NDArray at 0x81a5d68>,\n",
       " 'stage2_unit1_bn2_gamma': <mxnet.ndarray.NDArray at 0x8185470>,\n",
       " 'stage2_unit1_bn3_beta': <mxnet.ndarray.NDArray at 0x81a58d0>,\n",
       " 'stage2_unit1_bn3_gamma': <mxnet.ndarray.NDArray at 0x819c0b8>,\n",
       " 'stage2_unit1_conv1_weight': <mxnet.ndarray.NDArray at 0x283d6a0>,\n",
       " 'stage2_unit1_conv2_weight': <mxnet.ndarray.NDArray at 0x819c048>,\n",
       " 'stage2_unit1_conv3_weight': <mxnet.ndarray.NDArray at 0x8185f28>,\n",
       " 'stage2_unit1_sc_weight': <mxnet.ndarray.NDArray at 0x8185eb8>,\n",
       " 'stage2_unit2_bn1_beta': <mxnet.ndarray.NDArray at 0x819cc18>,\n",
       " 'stage2_unit2_bn1_gamma': <mxnet.ndarray.NDArray at 0x819ce10>,\n",
       " 'stage2_unit2_bn2_beta': <mxnet.ndarray.NDArray at 0x8194860>,\n",
       " 'stage2_unit2_bn2_gamma': <mxnet.ndarray.NDArray at 0x8194b70>,\n",
       " 'stage2_unit2_bn3_beta': <mxnet.ndarray.NDArray at 0x8194438>,\n",
       " 'stage2_unit2_bn3_gamma': <mxnet.ndarray.NDArray at 0x81a55c0>,\n",
       " 'stage2_unit2_conv1_weight': <mxnet.ndarray.NDArray at 0x81af160>,\n",
       " 'stage2_unit2_conv2_weight': <mxnet.ndarray.NDArray at 0x81a50f0>,\n",
       " 'stage2_unit2_conv3_weight': <mxnet.ndarray.NDArray at 0x819c518>,\n",
       " 'stage2_unit3_bn1_beta': <mxnet.ndarray.NDArray at 0x81a52b0>,\n",
       " 'stage2_unit3_bn1_gamma': <mxnet.ndarray.NDArray at 0x8194ef0>,\n",
       " 'stage2_unit3_bn2_beta': <mxnet.ndarray.NDArray at 0x8194d30>,\n",
       " 'stage2_unit3_bn2_gamma': <mxnet.ndarray.NDArray at 0x283db38>,\n",
       " 'stage2_unit3_bn3_beta': <mxnet.ndarray.NDArray at 0x81a5630>,\n",
       " 'stage2_unit3_bn3_gamma': <mxnet.ndarray.NDArray at 0x8185cc0>,\n",
       " 'stage2_unit3_conv1_weight': <mxnet.ndarray.NDArray at 0x81a5cc0>,\n",
       " 'stage2_unit3_conv2_weight': <mxnet.ndarray.NDArray at 0x819c438>,\n",
       " 'stage2_unit3_conv3_weight': <mxnet.ndarray.NDArray at 0x819ca58>,\n",
       " 'stage2_unit4_bn1_beta': <mxnet.ndarray.NDArray at 0x81a5a90>,\n",
       " 'stage2_unit4_bn1_gamma': <mxnet.ndarray.NDArray at 0x819c198>,\n",
       " 'stage2_unit4_bn2_beta': <mxnet.ndarray.NDArray at 0x81a5550>,\n",
       " 'stage2_unit4_bn2_gamma': <mxnet.ndarray.NDArray at 0x819c128>,\n",
       " 'stage2_unit4_bn3_beta': <mxnet.ndarray.NDArray at 0x81942b0>,\n",
       " 'stage2_unit4_bn3_gamma': <mxnet.ndarray.NDArray at 0x81a59b0>,\n",
       " 'stage2_unit4_conv1_weight': <mxnet.ndarray.NDArray at 0x819c978>,\n",
       " 'stage2_unit4_conv2_weight': <mxnet.ndarray.NDArray at 0x81a5128>,\n",
       " 'stage2_unit4_conv3_weight': <mxnet.ndarray.NDArray at 0x819c668>,\n",
       " 'stage3_unit1_bn1_beta': <mxnet.ndarray.NDArray at 0x8194828>,\n",
       " 'stage3_unit1_bn1_gamma': <mxnet.ndarray.NDArray at 0x8194fd0>,\n",
       " 'stage3_unit1_bn2_beta': <mxnet.ndarray.NDArray at 0x81a5e80>,\n",
       " 'stage3_unit1_bn2_gamma': <mxnet.ndarray.NDArray at 0x81a5f60>,\n",
       " 'stage3_unit1_bn3_beta': <mxnet.ndarray.NDArray at 0x81a5b00>,\n",
       " 'stage3_unit1_bn3_gamma': <mxnet.ndarray.NDArray at 0x81a5048>,\n",
       " 'stage3_unit1_conv1_weight': <mxnet.ndarray.NDArray at 0x81a53c8>,\n",
       " 'stage3_unit1_conv2_weight': <mxnet.ndarray.NDArray at 0x283df98>,\n",
       " 'stage3_unit1_conv3_weight': <mxnet.ndarray.NDArray at 0x81a5390>,\n",
       " 'stage3_unit1_sc_weight': <mxnet.ndarray.NDArray at 0x81a5c50>,\n",
       " 'stage3_unit2_bn1_beta': <mxnet.ndarray.NDArray at 0x81941d0>,\n",
       " 'stage3_unit2_bn1_gamma': <mxnet.ndarray.NDArray at 0x819cb00>,\n",
       " 'stage3_unit2_bn2_beta': <mxnet.ndarray.NDArray at 0x81949b0>,\n",
       " 'stage3_unit2_bn2_gamma': <mxnet.ndarray.NDArray at 0x819cb70>,\n",
       " 'stage3_unit2_bn3_beta': <mxnet.ndarray.NDArray at 0x81a5ac8>,\n",
       " 'stage3_unit2_bn3_gamma': <mxnet.ndarray.NDArray at 0x81a54a8>,\n",
       " 'stage3_unit2_conv1_weight': <mxnet.ndarray.NDArray at 0x8194240>,\n",
       " 'stage3_unit2_conv2_weight': <mxnet.ndarray.NDArray at 0x819ca20>,\n",
       " 'stage3_unit2_conv3_weight': <mxnet.ndarray.NDArray at 0x819c6d8>,\n",
       " 'stage3_unit3_bn1_beta': <mxnet.ndarray.NDArray at 0x81af0b8>,\n",
       " 'stage3_unit3_bn1_gamma': <mxnet.ndarray.NDArray at 0x8194390>,\n",
       " 'stage3_unit3_bn2_beta': <mxnet.ndarray.NDArray at 0x819c780>,\n",
       " 'stage3_unit3_bn2_gamma': <mxnet.ndarray.NDArray at 0x81a57f0>,\n",
       " 'stage3_unit3_bn3_beta': <mxnet.ndarray.NDArray at 0x81a55f8>,\n",
       " 'stage3_unit3_bn3_gamma': <mxnet.ndarray.NDArray at 0x8194940>,\n",
       " 'stage3_unit3_conv1_weight': <mxnet.ndarray.NDArray at 0x8194320>,\n",
       " 'stage3_unit3_conv2_weight': <mxnet.ndarray.NDArray at 0x81af0f0>,\n",
       " 'stage3_unit3_conv3_weight': <mxnet.ndarray.NDArray at 0x8185da0>,\n",
       " 'stage3_unit4_bn1_beta': <mxnet.ndarray.NDArray at 0x81af2b0>,\n",
       " 'stage3_unit4_bn1_gamma': <mxnet.ndarray.NDArray at 0x81940f0>,\n",
       " 'stage3_unit4_bn2_beta': <mxnet.ndarray.NDArray at 0x819c828>,\n",
       " 'stage3_unit4_bn2_gamma': <mxnet.ndarray.NDArray at 0x81940b8>,\n",
       " 'stage3_unit4_bn3_beta': <mxnet.ndarray.NDArray at 0x8194b38>,\n",
       " 'stage3_unit4_bn3_gamma': <mxnet.ndarray.NDArray at 0x81a5470>,\n",
       " 'stage3_unit4_conv1_weight': <mxnet.ndarray.NDArray at 0x8194cc0>,\n",
       " 'stage3_unit4_conv2_weight': <mxnet.ndarray.NDArray at 0x81944a8>,\n",
       " 'stage3_unit4_conv3_weight': <mxnet.ndarray.NDArray at 0x819cdd8>,\n",
       " 'stage3_unit5_bn1_beta': <mxnet.ndarray.NDArray at 0x8185fd0>,\n",
       " 'stage3_unit5_bn1_gamma': <mxnet.ndarray.NDArray at 0x283dd30>,\n",
       " 'stage3_unit5_bn2_beta': <mxnet.ndarray.NDArray at 0x819c1d0>,\n",
       " 'stage3_unit5_bn2_gamma': <mxnet.ndarray.NDArray at 0x81af1d0>,\n",
       " 'stage3_unit5_bn3_beta': <mxnet.ndarray.NDArray at 0x81a5908>,\n",
       " 'stage3_unit5_bn3_gamma': <mxnet.ndarray.NDArray at 0x81a5710>,\n",
       " 'stage3_unit5_conv1_weight': <mxnet.ndarray.NDArray at 0x819cba8>,\n",
       " 'stage3_unit5_conv2_weight': <mxnet.ndarray.NDArray at 0x819cf60>,\n",
       " 'stage3_unit5_conv3_weight': <mxnet.ndarray.NDArray at 0x819c0f0>,\n",
       " 'stage3_unit6_bn1_beta': <mxnet.ndarray.NDArray at 0x8194c88>,\n",
       " 'stage3_unit6_bn1_gamma': <mxnet.ndarray.NDArray at 0x8194358>,\n",
       " 'stage3_unit6_bn2_beta': <mxnet.ndarray.NDArray at 0x819c080>,\n",
       " 'stage3_unit6_bn2_gamma': <mxnet.ndarray.NDArray at 0x81a5da0>,\n",
       " 'stage3_unit6_bn3_beta': <mxnet.ndarray.NDArray at 0x283dcc0>,\n",
       " 'stage3_unit6_bn3_gamma': <mxnet.ndarray.NDArray at 0x81a52e8>,\n",
       " 'stage3_unit6_conv1_weight': <mxnet.ndarray.NDArray at 0x819c400>,\n",
       " 'stage3_unit6_conv2_weight': <mxnet.ndarray.NDArray at 0x81a5b38>,\n",
       " 'stage3_unit6_conv3_weight': <mxnet.ndarray.NDArray at 0x8185dd8>,\n",
       " 'stage4_unit1_bn1_beta': <mxnet.ndarray.NDArray at 0x8194cf8>,\n",
       " 'stage4_unit1_bn1_gamma': <mxnet.ndarray.NDArray at 0x81945f8>,\n",
       " 'stage4_unit1_bn2_beta': <mxnet.ndarray.NDArray at 0x8185ef0>,\n",
       " 'stage4_unit1_bn2_gamma': <mxnet.ndarray.NDArray at 0x81a5f28>,\n",
       " 'stage4_unit1_bn3_beta': <mxnet.ndarray.NDArray at 0x81a5d30>,\n",
       " 'stage4_unit1_bn3_gamma': <mxnet.ndarray.NDArray at 0x8194e48>,\n",
       " 'stage4_unit1_conv1_weight': <mxnet.ndarray.NDArray at 0x819cc50>,\n",
       " 'stage4_unit1_conv2_weight': <mxnet.ndarray.NDArray at 0x81947b8>,\n",
       " 'stage4_unit1_conv3_weight': <mxnet.ndarray.NDArray at 0x81942e8>,\n",
       " 'stage4_unit1_sc_weight': <mxnet.ndarray.NDArray at 0x81a59e8>,\n",
       " 'stage4_unit2_bn1_beta': <mxnet.ndarray.NDArray at 0x283def0>,\n",
       " 'stage4_unit2_bn1_gamma': <mxnet.ndarray.NDArray at 0x81a5898>,\n",
       " 'stage4_unit2_bn2_beta': <mxnet.ndarray.NDArray at 0x8194630>,\n",
       " 'stage4_unit2_bn2_gamma': <mxnet.ndarray.NDArray at 0x81947f0>,\n",
       " 'stage4_unit2_bn3_beta': <mxnet.ndarray.NDArray at 0x81946a0>,\n",
       " 'stage4_unit2_bn3_gamma': <mxnet.ndarray.NDArray at 0x8194160>,\n",
       " 'stage4_unit2_conv1_weight': <mxnet.ndarray.NDArray at 0x81854a8>,\n",
       " 'stage4_unit2_conv2_weight': <mxnet.ndarray.NDArray at 0x81a51d0>,\n",
       " 'stage4_unit2_conv3_weight': <mxnet.ndarray.NDArray at 0x81a5860>,\n",
       " 'stage4_unit3_bn1_beta': <mxnet.ndarray.NDArray at 0x81a5668>,\n",
       " 'stage4_unit3_bn1_gamma': <mxnet.ndarray.NDArray at 0x819c630>,\n",
       " 'stage4_unit3_bn2_beta': <mxnet.ndarray.NDArray at 0x8185e80>,\n",
       " 'stage4_unit3_bn2_gamma': <mxnet.ndarray.NDArray at 0x819c2b0>,\n",
       " 'stage4_unit3_bn3_beta': <mxnet.ndarray.NDArray at 0x819c9e8>,\n",
       " 'stage4_unit3_bn3_gamma': <mxnet.ndarray.NDArray at 0x8194748>,\n",
       " 'stage4_unit3_conv1_weight': <mxnet.ndarray.NDArray at 0x819ccc0>,\n",
       " 'stage4_unit3_conv2_weight': <mxnet.ndarray.NDArray at 0x81a5be0>,\n",
       " 'stage4_unit3_conv3_weight': <mxnet.ndarray.NDArray at 0x819cfd0>}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arg_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "while auxiliaries contains the the mean and std for the batch normalization layers.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bn0_moving_mean': <NDArray 64 @gpu(0)>,\n",
       " 'bn0_moving_var': <NDArray 64 @gpu(0)>,\n",
       " 'bn1_moving_mean': <NDArray 2048 @gpu(0)>,\n",
       " 'bn1_moving_var': <NDArray 2048 @gpu(0)>,\n",
       " 'bn_data_moving_mean': <NDArray 3 @gpu(0)>,\n",
       " 'bn_data_moving_var': <NDArray 3 @gpu(0)>,\n",
       " 'stage1_unit1_bn1_moving_mean': <NDArray 64 @gpu(0)>,\n",
       " 'stage1_unit1_bn1_moving_var': <NDArray 64 @gpu(0)>,\n",
       " 'stage1_unit1_bn2_moving_mean': <NDArray 64 @gpu(0)>,\n",
       " 'stage1_unit1_bn2_moving_var': <NDArray 64 @gpu(0)>,\n",
       " 'stage1_unit1_bn3_moving_mean': <NDArray 64 @gpu(0)>,\n",
       " 'stage1_unit1_bn3_moving_var': <NDArray 64 @gpu(0)>,\n",
       " 'stage1_unit2_bn1_moving_mean': <NDArray 256 @gpu(0)>,\n",
       " 'stage1_unit2_bn1_moving_var': <NDArray 256 @gpu(0)>,\n",
       " 'stage1_unit2_bn2_moving_mean': <NDArray 64 @gpu(0)>,\n",
       " 'stage1_unit2_bn2_moving_var': <NDArray 64 @gpu(0)>,\n",
       " 'stage1_unit2_bn3_moving_mean': <NDArray 64 @gpu(0)>,\n",
       " 'stage1_unit2_bn3_moving_var': <NDArray 64 @gpu(0)>,\n",
       " 'stage1_unit3_bn1_moving_mean': <NDArray 256 @gpu(0)>,\n",
       " 'stage1_unit3_bn1_moving_var': <NDArray 256 @gpu(0)>,\n",
       " 'stage1_unit3_bn2_moving_mean': <NDArray 64 @gpu(0)>,\n",
       " 'stage1_unit3_bn2_moving_var': <NDArray 64 @gpu(0)>,\n",
       " 'stage1_unit3_bn3_moving_mean': <NDArray 64 @gpu(0)>,\n",
       " 'stage1_unit3_bn3_moving_var': <NDArray 64 @gpu(0)>,\n",
       " 'stage2_unit1_bn1_moving_mean': <NDArray 256 @gpu(0)>,\n",
       " 'stage2_unit1_bn1_moving_var': <NDArray 256 @gpu(0)>,\n",
       " 'stage2_unit1_bn2_moving_mean': <NDArray 128 @gpu(0)>,\n",
       " 'stage2_unit1_bn2_moving_var': <NDArray 128 @gpu(0)>,\n",
       " 'stage2_unit1_bn3_moving_mean': <NDArray 128 @gpu(0)>,\n",
       " 'stage2_unit1_bn3_moving_var': <NDArray 128 @gpu(0)>,\n",
       " 'stage2_unit2_bn1_moving_mean': <NDArray 512 @gpu(0)>,\n",
       " 'stage2_unit2_bn1_moving_var': <NDArray 512 @gpu(0)>,\n",
       " 'stage2_unit2_bn2_moving_mean': <NDArray 128 @gpu(0)>,\n",
       " 'stage2_unit2_bn2_moving_var': <NDArray 128 @gpu(0)>,\n",
       " 'stage2_unit2_bn3_moving_mean': <NDArray 128 @gpu(0)>,\n",
       " 'stage2_unit2_bn3_moving_var': <NDArray 128 @gpu(0)>,\n",
       " 'stage2_unit3_bn1_moving_mean': <NDArray 512 @gpu(0)>,\n",
       " 'stage2_unit3_bn1_moving_var': <NDArray 512 @gpu(0)>,\n",
       " 'stage2_unit3_bn2_moving_mean': <NDArray 128 @gpu(0)>,\n",
       " 'stage2_unit3_bn2_moving_var': <NDArray 128 @gpu(0)>,\n",
       " 'stage2_unit3_bn3_moving_mean': <NDArray 128 @gpu(0)>,\n",
       " 'stage2_unit3_bn3_moving_var': <NDArray 128 @gpu(0)>,\n",
       " 'stage2_unit4_bn1_moving_mean': <NDArray 512 @gpu(0)>,\n",
       " 'stage2_unit4_bn1_moving_var': <NDArray 512 @gpu(0)>,\n",
       " 'stage2_unit4_bn2_moving_mean': <NDArray 128 @gpu(0)>,\n",
       " 'stage2_unit4_bn2_moving_var': <NDArray 128 @gpu(0)>,\n",
       " 'stage2_unit4_bn3_moving_mean': <NDArray 128 @gpu(0)>,\n",
       " 'stage2_unit4_bn3_moving_var': <NDArray 128 @gpu(0)>,\n",
       " 'stage3_unit1_bn1_moving_mean': <NDArray 512 @gpu(0)>,\n",
       " 'stage3_unit1_bn1_moving_var': <NDArray 512 @gpu(0)>,\n",
       " 'stage3_unit1_bn2_moving_mean': <NDArray 256 @gpu(0)>,\n",
       " 'stage3_unit1_bn2_moving_var': <NDArray 256 @gpu(0)>,\n",
       " 'stage3_unit1_bn3_moving_mean': <NDArray 256 @gpu(0)>,\n",
       " 'stage3_unit1_bn3_moving_var': <NDArray 256 @gpu(0)>,\n",
       " 'stage3_unit2_bn1_moving_mean': <NDArray 1024 @gpu(0)>,\n",
       " 'stage3_unit2_bn1_moving_var': <NDArray 1024 @gpu(0)>,\n",
       " 'stage3_unit2_bn2_moving_mean': <NDArray 256 @gpu(0)>,\n",
       " 'stage3_unit2_bn2_moving_var': <NDArray 256 @gpu(0)>,\n",
       " 'stage3_unit2_bn3_moving_mean': <NDArray 256 @gpu(0)>,\n",
       " 'stage3_unit2_bn3_moving_var': <NDArray 256 @gpu(0)>,\n",
       " 'stage3_unit3_bn1_moving_mean': <NDArray 1024 @gpu(0)>,\n",
       " 'stage3_unit3_bn1_moving_var': <NDArray 1024 @gpu(0)>,\n",
       " 'stage3_unit3_bn2_moving_mean': <NDArray 256 @gpu(0)>,\n",
       " 'stage3_unit3_bn2_moving_var': <NDArray 256 @gpu(0)>,\n",
       " 'stage3_unit3_bn3_moving_mean': <NDArray 256 @gpu(0)>,\n",
       " 'stage3_unit3_bn3_moving_var': <NDArray 256 @gpu(0)>,\n",
       " 'stage3_unit4_bn1_moving_mean': <NDArray 1024 @gpu(0)>,\n",
       " 'stage3_unit4_bn1_moving_var': <NDArray 1024 @gpu(0)>,\n",
       " 'stage3_unit4_bn2_moving_mean': <NDArray 256 @gpu(0)>,\n",
       " 'stage3_unit4_bn2_moving_var': <NDArray 256 @gpu(0)>,\n",
       " 'stage3_unit4_bn3_moving_mean': <NDArray 256 @gpu(0)>,\n",
       " 'stage3_unit4_bn3_moving_var': <NDArray 256 @gpu(0)>,\n",
       " 'stage3_unit5_bn1_moving_mean': <NDArray 1024 @gpu(0)>,\n",
       " 'stage3_unit5_bn1_moving_var': <NDArray 1024 @gpu(0)>,\n",
       " 'stage3_unit5_bn2_moving_mean': <NDArray 256 @gpu(0)>,\n",
       " 'stage3_unit5_bn2_moving_var': <NDArray 256 @gpu(0)>,\n",
       " 'stage3_unit5_bn3_moving_mean': <NDArray 256 @gpu(0)>,\n",
       " 'stage3_unit5_bn3_moving_var': <NDArray 256 @gpu(0)>,\n",
       " 'stage3_unit6_bn1_moving_mean': <NDArray 1024 @gpu(0)>,\n",
       " 'stage3_unit6_bn1_moving_var': <NDArray 1024 @gpu(0)>,\n",
       " 'stage3_unit6_bn2_moving_mean': <NDArray 256 @gpu(0)>,\n",
       " 'stage3_unit6_bn2_moving_var': <NDArray 256 @gpu(0)>,\n",
       " 'stage3_unit6_bn3_moving_mean': <NDArray 256 @gpu(0)>,\n",
       " 'stage3_unit6_bn3_moving_var': <NDArray 256 @gpu(0)>,\n",
       " 'stage4_unit1_bn1_moving_mean': <NDArray 1024 @gpu(0)>,\n",
       " 'stage4_unit1_bn1_moving_var': <NDArray 1024 @gpu(0)>,\n",
       " 'stage4_unit1_bn2_moving_mean': <NDArray 512 @gpu(0)>,\n",
       " 'stage4_unit1_bn2_moving_var': <NDArray 512 @gpu(0)>,\n",
       " 'stage4_unit1_bn3_moving_mean': <NDArray 512 @gpu(0)>,\n",
       " 'stage4_unit1_bn3_moving_var': <NDArray 512 @gpu(0)>,\n",
       " 'stage4_unit2_bn1_moving_mean': <NDArray 2048 @gpu(0)>,\n",
       " 'stage4_unit2_bn1_moving_var': <NDArray 2048 @gpu(0)>,\n",
       " 'stage4_unit2_bn2_moving_mean': <NDArray 512 @gpu(0)>,\n",
       " 'stage4_unit2_bn2_moving_var': <NDArray 512 @gpu(0)>,\n",
       " 'stage4_unit2_bn3_moving_mean': <NDArray 512 @gpu(0)>,\n",
       " 'stage4_unit2_bn3_moving_var': <NDArray 512 @gpu(0)>,\n",
       " 'stage4_unit3_bn1_moving_mean': <NDArray 2048 @gpu(0)>,\n",
       " 'stage4_unit3_bn1_moving_var': <NDArray 2048 @gpu(0)>,\n",
       " 'stage4_unit3_bn2_moving_mean': <NDArray 512 @gpu(0)>,\n",
       " 'stage4_unit3_bn2_moving_var': <NDArray 512 @gpu(0)>,\n",
       " 'stage4_unit3_bn3_moving_mean': <NDArray 512 @gpu(0)>,\n",
       " 'stage4_unit3_bn3_moving_var': <NDArray 512 @gpu(0)>}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create an executable `module` (see [module.ipynb](../basic/module.ipynb)) on GPU 0. To use a difference device, we just need to charge the context, e.g. `mx.cpu()` for CPU and `mx.gpu(2)` for the 3rd GPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mod = mx.mod.Module(symbol=sym, context=mx.gpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ResNet is trained with RGB images of size 224 x 224. The training data is feed by the variable `data`. We bind the module with the input shape and specify that it is only for predicting. The number 1 added before the image shape (3x224x224) means that we will only predict one image each time. Next we set the loaded parameters. Now the module is ready to run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mod.bind(for_training = False,\n",
    "         data_shapes=[('data', (1,3,224,224))])\n",
    "mod.set_params(arg_params, aux_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data\n",
    "\n",
    "We first obtain the synset file, in which the i-th line contains the label for the i-th class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "download('http://data.mxnet.io/models/imagenet/resnet/synset.txt')\n",
    "with open('synset.txt') as f:\n",
    "    synsets = [l.rstrip() for l in f]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next download 1000 images for testing, which were not used for the training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tarfile\n",
    "download('http://data.mxnet.io/data/val_1000.tar')\n",
    "tfile = tarfile.open('val_1000.tar')\n",
    "tfile.extractall()\n",
    "with open('val_1000/label') as f:\n",
    "    val_label = [int(l.split('\\t')[0]) for l in f]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the first 8 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.rc(\"savefig\", dpi=100)\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "for i in range(0,8):\n",
    "    img = cv2.cvtColor(cv2.imread('val_1000/%d.jpg' % (i,)), cv2.COLOR_BGR2RGB)\n",
    "    plt.subplot(2,4,i+1)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    label = synsets[val_label[i]]\n",
    "    label = ' '.join(label.split(',')[0].split(' ')[1:])\n",
    "    plt.title(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define a function that reads one image each time and convert to a format can be used by the model. Here we use a naive way that resizes the original image into the desired shape, and change the data layout. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "def get_image(filename):\n",
    "    img = cv2.imread(filename)  # read image in b,g,r order\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)   # change to r,g,b order\n",
    "    img = cv2.resize(img, (224, 224))  # resize to 224*224 to fit model\n",
    "    img = np.swapaxes(img, 0, 2)\n",
    "    img = np.swapaxes(img, 1, 2)  # change to (channel, height, width)\n",
    "    img = img[np.newaxis, :]  # extend to (example, channel, heigth, width)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we define a input data structure which is acceptable by mxnet. The field `data` is used for the input data, which is a list of NDArrays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "Batch = namedtuple('Batch', ['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict\n",
    "\n",
    "Now we are ready to run the prediction by `forward`. Then we can get the output using `get_outputs`, in which the i-th element is the predicted probability that the image contains the i-th class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = get_image('val_1000/0.jpg')\n",
    "mod.forward(Batch([mx.nd.array(img)]))\n",
    "prob = mod.get_outputs()[0].asnumpy()\n",
    "y = np.argsort(np.squeeze(prob))[::-1]\n",
    "print('truth label %d; top-1 predict label %d' % (val_label[0], y[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When predicting more than one images, we can batch several images together which potentially improves the performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "mod2 = mx.mod.Module(symbol=sym, context=mx.gpu())\n",
    "mod2.bind(for_training=False, data_shapes=[('data', (batch_size,3,224,224))])\n",
    "mod2.set_params(arg_params, aux_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we iterative multiple images to calculate the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "acc = 0.0\n",
    "total = 0.0\n",
    "for i in range(0, 200/batch_size):\n",
    "    tic = time.time()\n",
    "    idx = range(i*batch_size, (i+1)*batch_size)\n",
    "    img = np.concatenate([get_image('val_1000/%d.jpg'%(j)) for j in idx])\n",
    "    mod2.forward(Batch([mx.nd.array(img)]))\n",
    "    prob = mod2.get_outputs()[0].asnumpy()\n",
    "    pred = np.argsort(prob, axis=1)\n",
    "    top1 = pred[:,-1]\n",
    "    acc += sum(top1 == np.array([val_label[j] for j in idx]))\n",
    "    total += len(idx)\n",
    "    print('batch %d, time %f sec'%(i, time.time()-tic))\n",
    "print('top-1 accuracy %f'%(acc/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Extract Features\n",
    "\n",
    "Sometime we want the internal outputs from a neural network rather than then final predicted probabilities. In this way, the neural network works as a feature extraction module to other applications. \n",
    "\n",
    "A loaded symbol in default only returns the last layer as output. But we can get all internal layers by `get_internals`, which returns a new symbol outputting all internal layers. The following codes print the last 10 layer names. \n",
    "\n",
    "We can also use `mx.viz.plot_network(sym)` to visually find the name of the layer we want to use. The name conventions of the output is the layer name with `_output` as the postfix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_layers = sym.get_internals()\n",
    "all_layers.list_outputs()[-10:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often we want to use the output before the last fully connected layers, which may return semantic features of the raw images but not too fitting to the label yet. In the ResNet case, it is the flatten layer with name `flatten0` before the last fullc layer. The following codes get the new symbol `sym3` which use the flatten layer as the last output layer, and initialize a new module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_layers = sym.get_internals()\n",
    "sym3 = all_layers['flatten0_output']\n",
    "mod3 = mx.mod.Module(symbol=sym3, context=mx.gpu())\n",
    "mod3.bind(for_training=False, data_shapes=[('data', (1,3,224,224))])\n",
    "mod3.set_params(arg_params, aux_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can do feature extraction using `forward1` as before. Notice that the last convolution layer uses 2048 channels, and we then perform an average pooling, so the output size of the flatten layer is 2048."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = get_image('val_1000/0.jpg')\n",
    "mod3.forward(Batch([mx.nd.array(img)]))\n",
    "out = mod3.get_outputs()[0].asnumpy()\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Readings\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
