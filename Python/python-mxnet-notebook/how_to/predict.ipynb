{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict and Extract Features with Pre-trained Models\n",
    "\n",
    "This tutorial will work through how to use pre-trained models for predicting and feature extraction.\n",
    "\n",
    "## Download pre-trained models\n",
    "\n",
    "A model often contains two parts, the `.json` file specifying the neural network structure, and the `.params` file containing the binary parameters. The name convention is `name-symbol.json` and `name-epoch.params`, where `name` is the model name, and `epoch` is the epoch number. \n",
    "\n",
    "\n",
    "Here we download a pre-trained Resnet 50-layer model on Imagenet. Other models are available at http://data.mxnet.io/models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, urllib\n",
    "def download(url):\n",
    "    filename = url.split(\"/\")[-1]\n",
    "    if not os.path.exists(filename):\n",
    "        urllib.urlretrieve(url, filename)\n",
    "def get_model(prefix, epoch):\n",
    "    download(prefix+'-symbol.json')\n",
    "    download(prefix+'-%04d.params' % (epoch,))\n",
    "\n",
    "get_model('http://data.mxnet.io/models/imagenet/resnet/50-layers/resnet-50', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "\n",
    "We first load the model into memory with `load_checkpoint`. It returns the symbol (see [symbol.ipynb](../basic/symbol.ipynb)) definition of the neural network, and parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "sym, arg_params, aux_params = mx.model.load_checkpoint('resnet-50', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bn1_beta',\n",
       " 'bn1_output',\n",
       " 'relu1_output',\n",
       " 'pool1_output',\n",
       " 'flatten0_output',\n",
       " 'fc1_weight',\n",
       " 'fc1_bias',\n",
       " 'fc1_output',\n",
       " 'softmax_label']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "internals = sym.get_internals()\n",
    "internals.list_outputs()[-10:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the neural network by `mx.viz.plot_network`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "failed to execute ['dot', '-Tsvg'], make sure the Graphviz executables are on your systems' path",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32mc:\\Anaconda2\\lib\\site-packages\\IPython\\core\\formatters.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\Anaconda2\\lib\\site-packages\\graphviz\\files.pyc\u001b[0m in \u001b[0;36m_repr_svg_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_repr_svg_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'svg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_encoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\Anaconda2\\lib\\site-packages\\graphviz\\files.pyc\u001b[0m in \u001b[0;36mpipe\u001b[0;34m(self, format)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_encoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\Anaconda2\\lib\\site-packages\\graphviz\\backend.pyc\u001b[0m in \u001b[0;36mpipe\u001b[0;34m(engine, format, data)\u001b[0m\n\u001b[1;32m    126\u001b[0m             raise RuntimeError('failed to execute %r, '\n\u001b[1;32m    127\u001b[0m                 \u001b[1;34m'make sure the Graphviz executables '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                 'are on your systems\\' path' % args)\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pragma: no cover\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: failed to execute ['dot', '-Tsvg'], make sure the Graphviz executables are on your systems' path"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<graphviz.dot.Digraph at 0x18d040b8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "mx.viz.plot_network(sym)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both argument parameters and auxiliary parameters (e.g mean/std in batch normalization layer) are stored as a dictionary of string name and ndarray value (see [ndarray.ipynb](../basic/ndarray.ipynb)). The arguments contain \n",
    "consist of weight and bias. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bn0_beta': <mxnet.ndarray.NDArray at 0x803e908>,\n",
       " 'bn0_gamma': <mxnet.ndarray.NDArray at 0x802a6d8>,\n",
       " 'bn1_beta': <mxnet.ndarray.NDArray at 0x8035d30>,\n",
       " 'bn1_gamma': <mxnet.ndarray.NDArray at 0x803e2e8>,\n",
       " 'bn_data_beta': <mxnet.ndarray.NDArray at 0x8020518>,\n",
       " 'bn_data_gamma': <mxnet.ndarray.NDArray at 0x80356d8>,\n",
       " 'conv0_weight': <mxnet.ndarray.NDArray at 0x802a8d0>,\n",
       " 'fc1_bias': <mxnet.ndarray.NDArray at 0x80357b8>,\n",
       " 'fc1_weight': <mxnet.ndarray.NDArray at 0x803e828>,\n",
       " 'stage1_unit1_bn1_beta': <mxnet.ndarray.NDArray at 0x8035a90>,\n",
       " 'stage1_unit1_bn1_gamma': <mxnet.ndarray.NDArray at 0x8035160>,\n",
       " 'stage1_unit1_bn2_beta': <mxnet.ndarray.NDArray at 0x80359b0>,\n",
       " 'stage1_unit1_bn2_gamma': <mxnet.ndarray.NDArray at 0x802a358>,\n",
       " 'stage1_unit1_bn3_beta': <mxnet.ndarray.NDArray at 0x80354a8>,\n",
       " 'stage1_unit1_bn3_gamma': <mxnet.ndarray.NDArray at 0x80359e8>,\n",
       " 'stage1_unit1_conv1_weight': <mxnet.ndarray.NDArray at 0x802a080>,\n",
       " 'stage1_unit1_conv2_weight': <mxnet.ndarray.NDArray at 0x8020e48>,\n",
       " 'stage1_unit1_conv3_weight': <mxnet.ndarray.NDArray at 0x80208d0>,\n",
       " 'stage1_unit1_sc_weight': <mxnet.ndarray.NDArray at 0x80200f0>,\n",
       " 'stage1_unit2_bn1_beta': <mxnet.ndarray.NDArray at 0x803eac8>,\n",
       " 'stage1_unit2_bn1_gamma': <mxnet.ndarray.NDArray at 0x803e2b0>,\n",
       " 'stage1_unit2_bn2_beta': <mxnet.ndarray.NDArray at 0x8035438>,\n",
       " 'stage1_unit2_bn2_gamma': <mxnet.ndarray.NDArray at 0x8035eb8>,\n",
       " 'stage1_unit2_bn3_beta': <mxnet.ndarray.NDArray at 0x8035860>,\n",
       " 'stage1_unit2_bn3_gamma': <mxnet.ndarray.NDArray at 0x8035240>,\n",
       " 'stage1_unit2_conv1_weight': <mxnet.ndarray.NDArray at 0x802ac18>,\n",
       " 'stage1_unit2_conv2_weight': <mxnet.ndarray.NDArray at 0x8020b38>,\n",
       " 'stage1_unit2_conv3_weight': <mxnet.ndarray.NDArray at 0x803eba8>,\n",
       " 'stage1_unit3_bn1_beta': <mxnet.ndarray.NDArray at 0x803e780>,\n",
       " 'stage1_unit3_bn1_gamma': <mxnet.ndarray.NDArray at 0x803e9b0>,\n",
       " 'stage1_unit3_bn2_beta': <mxnet.ndarray.NDArray at 0x802a0f0>,\n",
       " 'stage1_unit3_bn2_gamma': <mxnet.ndarray.NDArray at 0x8020978>,\n",
       " 'stage1_unit3_bn3_beta': <mxnet.ndarray.NDArray at 0x8020358>,\n",
       " 'stage1_unit3_bn3_gamma': <mxnet.ndarray.NDArray at 0x8035e10>,\n",
       " 'stage1_unit3_conv1_weight': <mxnet.ndarray.NDArray at 0x803e860>,\n",
       " 'stage1_unit3_conv2_weight': <mxnet.ndarray.NDArray at 0x802aeb8>,\n",
       " 'stage1_unit3_conv3_weight': <mxnet.ndarray.NDArray at 0x8020710>,\n",
       " 'stage2_unit1_bn1_beta': <mxnet.ndarray.NDArray at 0x803e940>,\n",
       " 'stage2_unit1_bn1_gamma': <mxnet.ndarray.NDArray at 0x8020da0>,\n",
       " 'stage2_unit1_bn2_beta': <mxnet.ndarray.NDArray at 0x803e6d8>,\n",
       " 'stage2_unit1_bn2_gamma': <mxnet.ndarray.NDArray at 0x8020160>,\n",
       " 'stage2_unit1_bn3_beta': <mxnet.ndarray.NDArray at 0x803e240>,\n",
       " 'stage2_unit1_bn3_gamma': <mxnet.ndarray.NDArray at 0x802a9e8>,\n",
       " 'stage2_unit1_conv1_weight': <mxnet.ndarray.NDArray at 0x8020860>,\n",
       " 'stage2_unit1_conv2_weight': <mxnet.ndarray.NDArray at 0x802a978>,\n",
       " 'stage2_unit1_conv3_weight': <mxnet.ndarray.NDArray at 0x80202e8>,\n",
       " 'stage2_unit1_sc_weight': <mxnet.ndarray.NDArray at 0x8020278>,\n",
       " 'stage2_unit2_bn1_beta': <mxnet.ndarray.NDArray at 0x8035588>,\n",
       " 'stage2_unit2_bn1_gamma': <mxnet.ndarray.NDArray at 0x8035780>,\n",
       " 'stage2_unit2_bn2_beta': <mxnet.ndarray.NDArray at 0x802a1d0>,\n",
       " 'stage2_unit2_bn2_gamma': <mxnet.ndarray.NDArray at 0x802a4e0>,\n",
       " 'stage2_unit2_bn3_beta': <mxnet.ndarray.NDArray at 0x8020d68>,\n",
       " 'stage2_unit2_bn3_gamma': <mxnet.ndarray.NDArray at 0x8035ef0>,\n",
       " 'stage2_unit2_conv1_weight': <mxnet.ndarray.NDArray at 0x803ea90>,\n",
       " 'stage2_unit2_conv2_weight': <mxnet.ndarray.NDArray at 0x8035a20>,\n",
       " 'stage2_unit2_conv3_weight': <mxnet.ndarray.NDArray at 0x802ae48>,\n",
       " 'stage2_unit3_bn1_beta': <mxnet.ndarray.NDArray at 0x8035be0>,\n",
       " 'stage2_unit3_bn1_gamma': <mxnet.ndarray.NDArray at 0x802a860>,\n",
       " 'stage2_unit3_bn2_beta': <mxnet.ndarray.NDArray at 0x802a6a0>,\n",
       " 'stage2_unit3_bn2_gamma': <mxnet.ndarray.NDArray at 0x80207f0>,\n",
       " 'stage2_unit3_bn3_beta': <mxnet.ndarray.NDArray at 0x8035f60>,\n",
       " 'stage2_unit3_bn3_gamma': <mxnet.ndarray.NDArray at 0x80200b8>,\n",
       " 'stage2_unit3_conv1_weight': <mxnet.ndarray.NDArray at 0x803e630>,\n",
       " 'stage2_unit3_conv2_weight': <mxnet.ndarray.NDArray at 0x802ad68>,\n",
       " 'stage2_unit3_conv3_weight': <mxnet.ndarray.NDArray at 0x80353c8>,\n",
       " 'stage2_unit4_bn1_beta': <mxnet.ndarray.NDArray at 0x803e400>,\n",
       " 'stage2_unit4_bn1_gamma': <mxnet.ndarray.NDArray at 0x802aac8>,\n",
       " 'stage2_unit4_bn2_beta': <mxnet.ndarray.NDArray at 0x8035e80>,\n",
       " 'stage2_unit4_bn2_gamma': <mxnet.ndarray.NDArray at 0x802aa58>,\n",
       " 'stage2_unit4_bn3_beta': <mxnet.ndarray.NDArray at 0x8020be0>,\n",
       " 'stage2_unit4_bn3_gamma': <mxnet.ndarray.NDArray at 0x803e320>,\n",
       " 'stage2_unit4_conv1_weight': <mxnet.ndarray.NDArray at 0x80352e8>,\n",
       " 'stage2_unit4_conv2_weight': <mxnet.ndarray.NDArray at 0x8035a58>,\n",
       " 'stage2_unit4_conv3_weight': <mxnet.ndarray.NDArray at 0x802af98>,\n",
       " 'stage3_unit1_bn1_beta': <mxnet.ndarray.NDArray at 0x802a198>,\n",
       " 'stage3_unit1_bn1_gamma': <mxnet.ndarray.NDArray at 0x802a940>,\n",
       " 'stage3_unit1_bn2_beta': <mxnet.ndarray.NDArray at 0x803e7f0>,\n",
       " 'stage3_unit1_bn2_gamma': <mxnet.ndarray.NDArray at 0x803e8d0>,\n",
       " 'stage3_unit1_bn3_beta': <mxnet.ndarray.NDArray at 0x803e470>,\n",
       " 'stage3_unit1_bn3_gamma': <mxnet.ndarray.NDArray at 0x8035978>,\n",
       " 'stage3_unit1_conv1_weight': <mxnet.ndarray.NDArray at 0x8035cf8>,\n",
       " 'stage3_unit1_conv2_weight': <mxnet.ndarray.NDArray at 0x8020828>,\n",
       " 'stage3_unit1_conv3_weight': <mxnet.ndarray.NDArray at 0x8035cc0>,\n",
       " 'stage3_unit1_sc_weight': <mxnet.ndarray.NDArray at 0x803e5c0>,\n",
       " 'stage3_unit2_bn1_beta': <mxnet.ndarray.NDArray at 0x8020b00>,\n",
       " 'stage3_unit2_bn1_gamma': <mxnet.ndarray.NDArray at 0x8035470>,\n",
       " 'stage3_unit2_bn2_beta': <mxnet.ndarray.NDArray at 0x802a320>,\n",
       " 'stage3_unit2_bn2_gamma': <mxnet.ndarray.NDArray at 0x80354e0>,\n",
       " 'stage3_unit2_bn3_beta': <mxnet.ndarray.NDArray at 0x803e438>,\n",
       " 'stage3_unit2_bn3_gamma': <mxnet.ndarray.NDArray at 0x8035dd8>,\n",
       " 'stage3_unit2_conv1_weight': <mxnet.ndarray.NDArray at 0x8020b70>,\n",
       " 'stage3_unit2_conv2_weight': <mxnet.ndarray.NDArray at 0x8035390>,\n",
       " 'stage3_unit2_conv3_weight': <mxnet.ndarray.NDArray at 0x8035048>,\n",
       " 'stage3_unit3_bn1_beta': <mxnet.ndarray.NDArray at 0x803e9e8>,\n",
       " 'stage3_unit3_bn1_gamma': <mxnet.ndarray.NDArray at 0x8020cc0>,\n",
       " 'stage3_unit3_bn2_beta': <mxnet.ndarray.NDArray at 0x80350f0>,\n",
       " 'stage3_unit3_bn2_gamma': <mxnet.ndarray.NDArray at 0x803e160>,\n",
       " 'stage3_unit3_bn3_beta': <mxnet.ndarray.NDArray at 0x8035f28>,\n",
       " 'stage3_unit3_bn3_gamma': <mxnet.ndarray.NDArray at 0x802a2b0>,\n",
       " 'stage3_unit3_conv1_weight': <mxnet.ndarray.NDArray at 0x8020c50>,\n",
       " 'stage3_unit3_conv2_weight': <mxnet.ndarray.NDArray at 0x803ea20>,\n",
       " 'stage3_unit3_conv3_weight': <mxnet.ndarray.NDArray at 0x8020198>,\n",
       " 'stage3_unit4_bn1_beta': <mxnet.ndarray.NDArray at 0x803ebe0>,\n",
       " 'stage3_unit4_bn1_gamma': <mxnet.ndarray.NDArray at 0x8020a20>,\n",
       " 'stage3_unit4_bn2_beta': <mxnet.ndarray.NDArray at 0x8035198>,\n",
       " 'stage3_unit4_bn2_gamma': <mxnet.ndarray.NDArray at 0x80209e8>,\n",
       " 'stage3_unit4_bn3_beta': <mxnet.ndarray.NDArray at 0x802a4a8>,\n",
       " 'stage3_unit4_bn3_gamma': <mxnet.ndarray.NDArray at 0x8035da0>,\n",
       " 'stage3_unit4_conv1_weight': <mxnet.ndarray.NDArray at 0x802a630>,\n",
       " 'stage3_unit4_conv2_weight': <mxnet.ndarray.NDArray at 0x8020dd8>,\n",
       " 'stage3_unit4_conv3_weight': <mxnet.ndarray.NDArray at 0x8035748>,\n",
       " 'stage3_unit5_bn1_beta': <mxnet.ndarray.NDArray at 0x8020390>,\n",
       " 'stage3_unit5_bn1_gamma': <mxnet.ndarray.NDArray at 0x8020780>,\n",
       " 'stage3_unit5_bn2_beta': <mxnet.ndarray.NDArray at 0x802ab00>,\n",
       " 'stage3_unit5_bn2_gamma': <mxnet.ndarray.NDArray at 0x803eb00>,\n",
       " 'stage3_unit5_bn3_beta': <mxnet.ndarray.NDArray at 0x803e278>,\n",
       " 'stage3_unit5_bn3_gamma': <mxnet.ndarray.NDArray at 0x803e080>,\n",
       " 'stage3_unit5_conv1_weight': <mxnet.ndarray.NDArray at 0x8035518>,\n",
       " 'stage3_unit5_conv2_weight': <mxnet.ndarray.NDArray at 0x80358d0>,\n",
       " 'stage3_unit5_conv3_weight': <mxnet.ndarray.NDArray at 0x802aa20>,\n",
       " 'stage3_unit6_bn1_beta': <mxnet.ndarray.NDArray at 0x802a5f8>,\n",
       " 'stage3_unit6_bn1_gamma': <mxnet.ndarray.NDArray at 0x8020c88>,\n",
       " 'stage3_unit6_bn2_beta': <mxnet.ndarray.NDArray at 0x802a9b0>,\n",
       " 'stage3_unit6_bn2_gamma': <mxnet.ndarray.NDArray at 0x803e710>,\n",
       " 'stage3_unit6_bn3_beta': <mxnet.ndarray.NDArray at 0x80206d8>,\n",
       " 'stage3_unit6_bn3_gamma': <mxnet.ndarray.NDArray at 0x8035c18>,\n",
       " 'stage3_unit6_conv1_weight': <mxnet.ndarray.NDArray at 0x802ad30>,\n",
       " 'stage3_unit6_conv2_weight': <mxnet.ndarray.NDArray at 0x803e4a8>,\n",
       " 'stage3_unit6_conv3_weight': <mxnet.ndarray.NDArray at 0x80201d0>,\n",
       " 'stage4_unit1_bn1_beta': <mxnet.ndarray.NDArray at 0x802a668>,\n",
       " 'stage4_unit1_bn1_gamma': <mxnet.ndarray.NDArray at 0x8020f28>,\n",
       " 'stage4_unit1_bn2_beta': <mxnet.ndarray.NDArray at 0x80202b0>,\n",
       " 'stage4_unit1_bn2_gamma': <mxnet.ndarray.NDArray at 0x803e898>,\n",
       " 'stage4_unit1_bn3_beta': <mxnet.ndarray.NDArray at 0x803e6a0>,\n",
       " 'stage4_unit1_bn3_gamma': <mxnet.ndarray.NDArray at 0x802a7b8>,\n",
       " 'stage4_unit1_conv1_weight': <mxnet.ndarray.NDArray at 0x80355c0>,\n",
       " 'stage4_unit1_conv2_weight': <mxnet.ndarray.NDArray at 0x802a128>,\n",
       " 'stage4_unit1_conv3_weight': <mxnet.ndarray.NDArray at 0x8020c18>,\n",
       " 'stage4_unit1_sc_weight': <mxnet.ndarray.NDArray at 0x803e358>,\n",
       " 'stage4_unit2_bn1_beta': <mxnet.ndarray.NDArray at 0x80205f8>,\n",
       " 'stage4_unit2_bn1_gamma': <mxnet.ndarray.NDArray at 0x803e208>,\n",
       " 'stage4_unit2_bn2_beta': <mxnet.ndarray.NDArray at 0x8020f60>,\n",
       " 'stage4_unit2_bn2_gamma': <mxnet.ndarray.NDArray at 0x802a160>,\n",
       " 'stage4_unit2_bn3_beta': <mxnet.ndarray.NDArray at 0x8020fd0>,\n",
       " 'stage4_unit2_bn3_gamma': <mxnet.ndarray.NDArray at 0x8020a90>,\n",
       " 'stage4_unit2_conv1_weight': <mxnet.ndarray.NDArray at 0x8020550>,\n",
       " 'stage4_unit2_conv2_weight': <mxnet.ndarray.NDArray at 0x8035b00>,\n",
       " 'stage4_unit2_conv3_weight': <mxnet.ndarray.NDArray at 0x803e1d0>,\n",
       " 'stage4_unit3_bn1_beta': <mxnet.ndarray.NDArray at 0x8035f98>,\n",
       " 'stage4_unit3_bn1_gamma': <mxnet.ndarray.NDArray at 0x802af60>,\n",
       " 'stage4_unit3_bn2_beta': <mxnet.ndarray.NDArray at 0x8020240>,\n",
       " 'stage4_unit3_bn2_gamma': <mxnet.ndarray.NDArray at 0x802abe0>,\n",
       " 'stage4_unit3_bn3_beta': <mxnet.ndarray.NDArray at 0x8035358>,\n",
       " 'stage4_unit3_bn3_gamma': <mxnet.ndarray.NDArray at 0x802a0b8>,\n",
       " 'stage4_unit3_conv1_weight': <mxnet.ndarray.NDArray at 0x8035630>,\n",
       " 'stage4_unit3_conv2_weight': <mxnet.ndarray.NDArray at 0x803e550>,\n",
       " 'stage4_unit3_conv3_weight': <mxnet.ndarray.NDArray at 0x8035940>}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arg_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "while auxiliaries contains the the mean and std for the batch normalization layers.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bn0_moving_mean': <NDArray 64 @gpu(0)>,\n",
       " 'bn0_moving_var': <NDArray 64 @gpu(0)>,\n",
       " 'bn1_moving_mean': <NDArray 2048 @gpu(0)>,\n",
       " 'bn1_moving_var': <NDArray 2048 @gpu(0)>,\n",
       " 'bn_data_moving_mean': <NDArray 3 @gpu(0)>,\n",
       " 'bn_data_moving_var': <NDArray 3 @gpu(0)>,\n",
       " 'stage1_unit1_bn1_moving_mean': <NDArray 64 @gpu(0)>,\n",
       " 'stage1_unit1_bn1_moving_var': <NDArray 64 @gpu(0)>,\n",
       " 'stage1_unit1_bn2_moving_mean': <NDArray 64 @gpu(0)>,\n",
       " 'stage1_unit1_bn2_moving_var': <NDArray 64 @gpu(0)>,\n",
       " 'stage1_unit1_bn3_moving_mean': <NDArray 64 @gpu(0)>,\n",
       " 'stage1_unit1_bn3_moving_var': <NDArray 64 @gpu(0)>,\n",
       " 'stage1_unit2_bn1_moving_mean': <NDArray 256 @gpu(0)>,\n",
       " 'stage1_unit2_bn1_moving_var': <NDArray 256 @gpu(0)>,\n",
       " 'stage1_unit2_bn2_moving_mean': <NDArray 64 @gpu(0)>,\n",
       " 'stage1_unit2_bn2_moving_var': <NDArray 64 @gpu(0)>,\n",
       " 'stage1_unit2_bn3_moving_mean': <NDArray 64 @gpu(0)>,\n",
       " 'stage1_unit2_bn3_moving_var': <NDArray 64 @gpu(0)>,\n",
       " 'stage1_unit3_bn1_moving_mean': <NDArray 256 @gpu(0)>,\n",
       " 'stage1_unit3_bn1_moving_var': <NDArray 256 @gpu(0)>,\n",
       " 'stage1_unit3_bn2_moving_mean': <NDArray 64 @gpu(0)>,\n",
       " 'stage1_unit3_bn2_moving_var': <NDArray 64 @gpu(0)>,\n",
       " 'stage1_unit3_bn3_moving_mean': <NDArray 64 @gpu(0)>,\n",
       " 'stage1_unit3_bn3_moving_var': <NDArray 64 @gpu(0)>,\n",
       " 'stage2_unit1_bn1_moving_mean': <NDArray 256 @gpu(0)>,\n",
       " 'stage2_unit1_bn1_moving_var': <NDArray 256 @gpu(0)>,\n",
       " 'stage2_unit1_bn2_moving_mean': <NDArray 128 @gpu(0)>,\n",
       " 'stage2_unit1_bn2_moving_var': <NDArray 128 @gpu(0)>,\n",
       " 'stage2_unit1_bn3_moving_mean': <NDArray 128 @gpu(0)>,\n",
       " 'stage2_unit1_bn3_moving_var': <NDArray 128 @gpu(0)>,\n",
       " 'stage2_unit2_bn1_moving_mean': <NDArray 512 @gpu(0)>,\n",
       " 'stage2_unit2_bn1_moving_var': <NDArray 512 @gpu(0)>,\n",
       " 'stage2_unit2_bn2_moving_mean': <NDArray 128 @gpu(0)>,\n",
       " 'stage2_unit2_bn2_moving_var': <NDArray 128 @gpu(0)>,\n",
       " 'stage2_unit2_bn3_moving_mean': <NDArray 128 @gpu(0)>,\n",
       " 'stage2_unit2_bn3_moving_var': <NDArray 128 @gpu(0)>,\n",
       " 'stage2_unit3_bn1_moving_mean': <NDArray 512 @gpu(0)>,\n",
       " 'stage2_unit3_bn1_moving_var': <NDArray 512 @gpu(0)>,\n",
       " 'stage2_unit3_bn2_moving_mean': <NDArray 128 @gpu(0)>,\n",
       " 'stage2_unit3_bn2_moving_var': <NDArray 128 @gpu(0)>,\n",
       " 'stage2_unit3_bn3_moving_mean': <NDArray 128 @gpu(0)>,\n",
       " 'stage2_unit3_bn3_moving_var': <NDArray 128 @gpu(0)>,\n",
       " 'stage2_unit4_bn1_moving_mean': <NDArray 512 @gpu(0)>,\n",
       " 'stage2_unit4_bn1_moving_var': <NDArray 512 @gpu(0)>,\n",
       " 'stage2_unit4_bn2_moving_mean': <NDArray 128 @gpu(0)>,\n",
       " 'stage2_unit4_bn2_moving_var': <NDArray 128 @gpu(0)>,\n",
       " 'stage2_unit4_bn3_moving_mean': <NDArray 128 @gpu(0)>,\n",
       " 'stage2_unit4_bn3_moving_var': <NDArray 128 @gpu(0)>,\n",
       " 'stage3_unit1_bn1_moving_mean': <NDArray 512 @gpu(0)>,\n",
       " 'stage3_unit1_bn1_moving_var': <NDArray 512 @gpu(0)>,\n",
       " 'stage3_unit1_bn2_moving_mean': <NDArray 256 @gpu(0)>,\n",
       " 'stage3_unit1_bn2_moving_var': <NDArray 256 @gpu(0)>,\n",
       " 'stage3_unit1_bn3_moving_mean': <NDArray 256 @gpu(0)>,\n",
       " 'stage3_unit1_bn3_moving_var': <NDArray 256 @gpu(0)>,\n",
       " 'stage3_unit2_bn1_moving_mean': <NDArray 1024 @gpu(0)>,\n",
       " 'stage3_unit2_bn1_moving_var': <NDArray 1024 @gpu(0)>,\n",
       " 'stage3_unit2_bn2_moving_mean': <NDArray 256 @gpu(0)>,\n",
       " 'stage3_unit2_bn2_moving_var': <NDArray 256 @gpu(0)>,\n",
       " 'stage3_unit2_bn3_moving_mean': <NDArray 256 @gpu(0)>,\n",
       " 'stage3_unit2_bn3_moving_var': <NDArray 256 @gpu(0)>,\n",
       " 'stage3_unit3_bn1_moving_mean': <NDArray 1024 @gpu(0)>,\n",
       " 'stage3_unit3_bn1_moving_var': <NDArray 1024 @gpu(0)>,\n",
       " 'stage3_unit3_bn2_moving_mean': <NDArray 256 @gpu(0)>,\n",
       " 'stage3_unit3_bn2_moving_var': <NDArray 256 @gpu(0)>,\n",
       " 'stage3_unit3_bn3_moving_mean': <NDArray 256 @gpu(0)>,\n",
       " 'stage3_unit3_bn3_moving_var': <NDArray 256 @gpu(0)>,\n",
       " 'stage3_unit4_bn1_moving_mean': <NDArray 1024 @gpu(0)>,\n",
       " 'stage3_unit4_bn1_moving_var': <NDArray 1024 @gpu(0)>,\n",
       " 'stage3_unit4_bn2_moving_mean': <NDArray 256 @gpu(0)>,\n",
       " 'stage3_unit4_bn2_moving_var': <NDArray 256 @gpu(0)>,\n",
       " 'stage3_unit4_bn3_moving_mean': <NDArray 256 @gpu(0)>,\n",
       " 'stage3_unit4_bn3_moving_var': <NDArray 256 @gpu(0)>,\n",
       " 'stage3_unit5_bn1_moving_mean': <NDArray 1024 @gpu(0)>,\n",
       " 'stage3_unit5_bn1_moving_var': <NDArray 1024 @gpu(0)>,\n",
       " 'stage3_unit5_bn2_moving_mean': <NDArray 256 @gpu(0)>,\n",
       " 'stage3_unit5_bn2_moving_var': <NDArray 256 @gpu(0)>,\n",
       " 'stage3_unit5_bn3_moving_mean': <NDArray 256 @gpu(0)>,\n",
       " 'stage3_unit5_bn3_moving_var': <NDArray 256 @gpu(0)>,\n",
       " 'stage3_unit6_bn1_moving_mean': <NDArray 1024 @gpu(0)>,\n",
       " 'stage3_unit6_bn1_moving_var': <NDArray 1024 @gpu(0)>,\n",
       " 'stage3_unit6_bn2_moving_mean': <NDArray 256 @gpu(0)>,\n",
       " 'stage3_unit6_bn2_moving_var': <NDArray 256 @gpu(0)>,\n",
       " 'stage3_unit6_bn3_moving_mean': <NDArray 256 @gpu(0)>,\n",
       " 'stage3_unit6_bn3_moving_var': <NDArray 256 @gpu(0)>,\n",
       " 'stage4_unit1_bn1_moving_mean': <NDArray 1024 @gpu(0)>,\n",
       " 'stage4_unit1_bn1_moving_var': <NDArray 1024 @gpu(0)>,\n",
       " 'stage4_unit1_bn2_moving_mean': <NDArray 512 @gpu(0)>,\n",
       " 'stage4_unit1_bn2_moving_var': <NDArray 512 @gpu(0)>,\n",
       " 'stage4_unit1_bn3_moving_mean': <NDArray 512 @gpu(0)>,\n",
       " 'stage4_unit1_bn3_moving_var': <NDArray 512 @gpu(0)>,\n",
       " 'stage4_unit2_bn1_moving_mean': <NDArray 2048 @gpu(0)>,\n",
       " 'stage4_unit2_bn1_moving_var': <NDArray 2048 @gpu(0)>,\n",
       " 'stage4_unit2_bn2_moving_mean': <NDArray 512 @gpu(0)>,\n",
       " 'stage4_unit2_bn2_moving_var': <NDArray 512 @gpu(0)>,\n",
       " 'stage4_unit2_bn3_moving_mean': <NDArray 512 @gpu(0)>,\n",
       " 'stage4_unit2_bn3_moving_var': <NDArray 512 @gpu(0)>,\n",
       " 'stage4_unit3_bn1_moving_mean': <NDArray 2048 @gpu(0)>,\n",
       " 'stage4_unit3_bn1_moving_var': <NDArray 2048 @gpu(0)>,\n",
       " 'stage4_unit3_bn2_moving_mean': <NDArray 512 @gpu(0)>,\n",
       " 'stage4_unit3_bn2_moving_var': <NDArray 512 @gpu(0)>,\n",
       " 'stage4_unit3_bn3_moving_mean': <NDArray 512 @gpu(0)>,\n",
       " 'stage4_unit3_bn3_moving_var': <NDArray 512 @gpu(0)>}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create an executable `module` (see [module.ipynb](../basic/module.ipynb)) on GPU 0. To use a difference device, we just need to charge the context, e.g. `mx.cpu()` for CPU and `mx.gpu(2)` for the 3rd GPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mod = mx.mod.Module(symbol=sym, context=mx.cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ResNet is trained with RGB images of size 224 x 224. The training data is feed by the variable `data`. We bind the module with the input shape and specify that it is only for predicting. The number 1 added before the image shape (3x224x224) means that we will only predict one image each time. Next we set the loaded parameters. Now the module is ready to run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mod.bind(for_training = False,\n",
    "         data_shapes=[('data', (1,3,224,224))])\n",
    "mod.set_params(arg_params, aux_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data\n",
    "\n",
    "We first obtain the synset file, in which the i-th line contains the label for the i-th class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'download' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-9a843ef9075c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'http://data.mxnet.io/models/imagenet/resnet/synset.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'synset.txt'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msynsets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'download' is not defined"
     ]
    }
   ],
   "source": [
    "download('http://data.mxnet.io/models/imagenet/resnet/synset.txt')\n",
    "with open('synset.txt') as f:\n",
    "    synsets = [l.rstrip() for l in f]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next download 1000 images for testing, which were not used for the training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tarfile\n",
    "download('http://data.mxnet.io/data/val_1000.tar')\n",
    "tfile = tarfile.open('val_1000.tar')\n",
    "tfile.extractall()\n",
    "with open('val_1000/label') as f:\n",
    "    val_label = [int(l.split('\\t')[0]) for l in f]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the first 8 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "..\\..\\..\\..\\opencv\\modules\\imgproc\\src\\color.cpp:3650: error: (-215) scn == 3 || scn == 4 in function cv::cvtColor\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-5956dcaaa96b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'val_1000/%d.jpg'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: ..\\..\\..\\..\\opencv\\modules\\imgproc\\src\\color.cpp:3650: error: (-215) scn == 3 || scn == 4 in function cv::cvtColor\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.rc(\"savefig\", dpi=100)\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "for i in range(0,8):\n",
    "    img = cv2.cvtColor(cv2.imread('val_1000/%d.jpg' % (i,)), cv2.COLOR_BGR2RGB)\n",
    "    plt.subplot(2,4,i+1)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    label = synsets[val_label[i]]\n",
    "    label = ' '.join(label.split(',')[0].split(' ')[1:])\n",
    "    plt.title(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define a function that reads one image each time and convert to a format can be used by the model. Here we use a naive way that resizes the original image into the desired shape, and change the data layout. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "def get_image(filename):\n",
    "    img = cv2.imread(filename)  # read image in b,g,r order\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)   # change to r,g,b order\n",
    "    img = cv2.resize(img, (224, 224))  # resize to 224*224 to fit model\n",
    "    img = np.swapaxes(img, 0, 2)\n",
    "    img = np.swapaxes(img, 1, 2)  # change to (channel, height, width)\n",
    "    img = img[np.newaxis, :]  # extend to (example, channel, heigth, width)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we define a input data structure which is acceptable by mxnet. The field `data` is used for the input data, which is a list of NDArrays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "Batch = namedtuple('Batch', ['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict\n",
    "\n",
    "Now we are ready to run the prediction by `forward`. Then we can get the output using `get_outputs`, in which the i-th element is the predicted probability that the image contains the i-th class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = get_image('val_1000/0.jpg')\n",
    "mod.forward(Batch([mx.nd.array(img)]))\n",
    "prob = mod.get_outputs()[0].asnumpy()\n",
    "y = np.argsort(np.squeeze(prob))[::-1]\n",
    "print('truth label %d; top-1 predict label %d' % (val_label[0], y[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When predicting more than one images, we can batch several images together which potentially improves the performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "mod2 = mx.mod.Module(symbol=sym, context=mx.gpu())\n",
    "mod2.bind(for_training=False, data_shapes=[('data', (batch_size,3,224,224))])\n",
    "mod2.set_params(arg_params, aux_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we iterative multiple images to calculate the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "acc = 0.0\n",
    "total = 0.0\n",
    "for i in range(0, 200/batch_size):\n",
    "    tic = time.time()\n",
    "    idx = range(i*batch_size, (i+1)*batch_size)\n",
    "    img = np.concatenate([get_image('val_1000/%d.jpg'%(j)) for j in idx])\n",
    "    mod2.forward(Batch([mx.nd.array(img)]))\n",
    "    prob = mod2.get_outputs()[0].asnumpy()\n",
    "    pred = np.argsort(prob, axis=1)\n",
    "    top1 = pred[:,-1]\n",
    "    acc += sum(top1 == np.array([val_label[j] for j in idx]))\n",
    "    total += len(idx)\n",
    "    print('batch %d, time %f sec'%(i, time.time()-tic))\n",
    "print('top-1 accuracy %f'%(acc/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Extract Features\n",
    "\n",
    "Sometime we want the internal outputs from a neural network rather than then final predicted probabilities. In this way, the neural network works as a feature extraction module to other applications. \n",
    "\n",
    "A loaded symbol in default only returns the last layer as output. But we can get all internal layers by `get_internals`, which returns a new symbol outputting all internal layers. The following codes print the last 10 layer names. \n",
    "\n",
    "We can also use `mx.viz.plot_network(sym)` to visually find the name of the layer we want to use. The name conventions of the output is the layer name with `_output` as the postfix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_layers = sym.get_internals()\n",
    "all_layers.list_outputs()[-10:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often we want to use the output before the last fully connected layers, which may return semantic features of the raw images but not too fitting to the label yet. In the ResNet case, it is the flatten layer with name `flatten0` before the last fullc layer. The following codes get the new symbol `sym3` which use the flatten layer as the last output layer, and initialize a new module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_layers = sym.get_internals()\n",
    "sym3 = all_layers['flatten0_output']\n",
    "mod3 = mx.mod.Module(symbol=sym3, context=mx.gpu())\n",
    "mod3.bind(for_training=False, data_shapes=[('data', (1,3,224,224))])\n",
    "mod3.set_params(arg_params, aux_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can do feature extraction using `forward1` as before. Notice that the last convolution layer uses 2048 channels, and we then perform an average pooling, so the output size of the flatten layer is 2048."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = get_image('val_1000/0.jpg')\n",
    "mod3.forward(Batch([mx.nd.array(img)]))\n",
    "out = mod3.get_outputs()[0].asnumpy()\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Readings\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
