{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune with Pre-trained Models\n",
    "\n",
    "In practice the dataset we use is relative small, so that we do not train an neural network from scratch, namely staring from random initialized parameters. Instead, it is common to train a neural network on a large-scale dataset and then use it either as an initialization or a fixed feature extractor. On [predict.ipynb](./predict.ipynb) we explained how to do the feature extraction, this tutorial will focus on how to use pre-trained model to fine tune a new network.\n",
    "\n",
    "The idea of fine-tune is that, we take a pre-trained model, replace the last fully-connected layer with new one, which outputs the desired number of classes and initializes with random values. Then we train as normal except that we may often use a smaller learning rate since we may already very close the final result. \n",
    "\n",
    "We will use pre-trained models on the Imagenet dataset to fine-tune the smaller caltech-256 dataset as an example. But note that it can be used to other datasets as well, even for quite different applications such as face identification. \n",
    "\n",
    "We will show that, even with simple hyper-parameters setting, we can match and even outperform state-of-the-art results on caltech-256.\n",
    "\n",
    "| Network | Accuracy | \n",
    "| --- | --- | \n",
    "| Resnet-50 | 77.4% | \n",
    "| Resnet-152 | 86.4% | \n",
    "\n",
    "## Prepare data\n",
    "\n",
    "We follow the standard protocal to sample 60 images from each class as the training set, and the rest for the validation set. We resize images into 256x256 size and pack them into the rec file. The scripts to prepare the data is as following. \n",
    "\n",
    "\n",
    "```sh\n",
    "wget http://www.vision.caltech.edu/Image_Datasets/Caltech256/256_ObjectCategories.tar\n",
    "tar -xf 256_ObjectCategories.tar\n",
    "\n",
    "mkdir -p caltech_256_train_60\n",
    "for i in 256_ObjectCategories/*; do\n",
    "    c=`basename $i`\n",
    "    mkdir -p caltech_256_train_60/$c\n",
    "    for j in `ls $i/*.jpg | shuf | head -n 60`; do\n",
    "        mv $j caltech_256_train_60/$c/\n",
    "    done\n",
    "done\n",
    "\n",
    "python ~/mxnet/tools/im2rec.py --list True --recursive True caltech-256-60-train caltech_256_train_60/\n",
    "python ~/mxnet/tools/im2rec.py --list True --recursive True caltech-256-60-val 256_ObjectCategories/\n",
    "python ~/mxnet/tools/im2rec.py --resize 256 --quality 90 --num-thread 16 caltech-256-60-val 256_ObjectCategories/\n",
    "python ~/mxnet/tools/im2rec.py --resize 256 --quality 90 --num-thread 16 caltech-256-60-train caltech_256_train_60/\n",
    "```\n",
    "\n",
    "The following codes download the pre-generated rec files. It may take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import os, urllib\n",
    "#def download(url):\n",
    "#    filename = url.split(\"/\")[-1]\n",
    "#    if not os.path.exists(filename):\n",
    "#        urllib.urlretrieve(url, filename)\n",
    "#download('http://data.mxnet.io/data/caltech-256/caltech-256-60-train.rec')\n",
    "#download('http://data.mxnet.io/data/caltech-256/caltech-256-60-val.rec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Next we define the function which returns the data iterators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "\n",
    "def get_iterators(batch_size, data_shape=(3, 224, 224)):\n",
    "    train = mx.io.ImageRecordIter(\n",
    "        path_imgrec         = 'caltech-256-60-train.rec',\n",
    "        data_name           = 'data',\n",
    "        label_name          = 'softmax_label',\n",
    "        batch_size          = batch_size,\n",
    "        data_shape          = data_shape,\n",
    "        shuffle             = True,\n",
    "        rand_crop           = True,\n",
    "        rand_mirror         = True)\n",
    "    val = mx.io.ImageRecordIter(\n",
    "        path_imgrec         = 'caltech-256-60-val.rec',\n",
    "        data_name           = 'data',\n",
    "        label_name          = 'softmax_label',\n",
    "        batch_size          = batch_size,\n",
    "        data_shape          = data_shape,\n",
    "        rand_crop           = False,\n",
    "        rand_mirror         = False)\n",
    "    return (train, val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then download a pretrained 50-layer ResNet model and load into memory. \n",
    "\n",
    "Note. If `load_checkpoint` reports error, we can remove the downloaded files and try `get_model` again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#def get_model(prefix, epoch):\n",
    "#    download(prefix+'-symbol.json')\n",
    "#    download(prefix+'-%04d.params' % (epoch,))\n",
    "\n",
    "# get_model('http://data.mxnet.io/models/imagenet/resnet/50-layers/resnet-50', 0)\n",
    "sym, arg_params, aux_params = mx.model.load_checkpoint('resnet-50', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<mxnet.symbol.Symbol at 0x81d9f60>,\n",
       " {'bn0_beta': <mxnet.ndarray.NDArray at 0x8263198>,\n",
       "  'bn0_gamma': <mxnet.ndarray.NDArray at 0x81a8f28>,\n",
       "  'bn1_beta': <mxnet.ndarray.NDArray at 0x81bc5c0>,\n",
       "  'bn1_gamma': <mxnet.ndarray.NDArray at 0x81bcb38>,\n",
       "  'bn_data_beta': <mxnet.ndarray.NDArray at 0x81a5d68>,\n",
       "  'bn_data_gamma': <mxnet.ndarray.NDArray at 0x81b1f28>,\n",
       "  'conv0_weight': <mxnet.ndarray.NDArray at 0x81b1160>,\n",
       "  'fc1_bias': <mxnet.ndarray.NDArray at 0x81bc048>,\n",
       "  'fc1_weight': <mxnet.ndarray.NDArray at 0x82630b8>,\n",
       "  'stage1_unit1_bn1_beta': <mxnet.ndarray.NDArray at 0x81bc320>,\n",
       "  'stage1_unit1_bn1_gamma': <mxnet.ndarray.NDArray at 0x81b19b0>,\n",
       "  'stage1_unit1_bn2_beta': <mxnet.ndarray.NDArray at 0x81bc240>,\n",
       "  'stage1_unit1_bn2_gamma': <mxnet.ndarray.NDArray at 0x81a8ba8>,\n",
       "  'stage1_unit1_bn3_beta': <mxnet.ndarray.NDArray at 0x81b1cf8>,\n",
       "  'stage1_unit1_bn3_gamma': <mxnet.ndarray.NDArray at 0x81bc278>,\n",
       "  'stage1_unit1_conv1_weight': <mxnet.ndarray.NDArray at 0x81a88d0>,\n",
       "  'stage1_unit1_conv2_weight': <mxnet.ndarray.NDArray at 0x81a86d8>,\n",
       "  'stage1_unit1_conv3_weight': <mxnet.ndarray.NDArray at 0x81a8160>,\n",
       "  'stage1_unit1_sc_weight': <mxnet.ndarray.NDArray at 0x8218940>,\n",
       "  'stage1_unit2_bn1_beta': <mxnet.ndarray.NDArray at 0x8263358>,\n",
       "  'stage1_unit2_bn1_gamma': <mxnet.ndarray.NDArray at 0x81bcb00>,\n",
       "  'stage1_unit2_bn2_beta': <mxnet.ndarray.NDArray at 0x81b1c88>,\n",
       "  'stage1_unit2_bn2_gamma': <mxnet.ndarray.NDArray at 0x81bc748>,\n",
       "  'stage1_unit2_bn3_beta': <mxnet.ndarray.NDArray at 0x81bc0f0>,\n",
       "  'stage1_unit2_bn3_gamma': <mxnet.ndarray.NDArray at 0x81b1a90>,\n",
       "  'stage1_unit2_conv1_weight': <mxnet.ndarray.NDArray at 0x81b14a8>,\n",
       "  'stage1_unit2_conv2_weight': <mxnet.ndarray.NDArray at 0x81a83c8>,\n",
       "  'stage1_unit2_conv3_weight': <mxnet.ndarray.NDArray at 0x8263438>,\n",
       "  'stage1_unit3_bn1_beta': <mxnet.ndarray.NDArray at 0x81bcfd0>,\n",
       "  'stage1_unit3_bn1_gamma': <mxnet.ndarray.NDArray at 0x8263240>,\n",
       "  'stage1_unit3_bn2_beta': <mxnet.ndarray.NDArray at 0x81a8940>,\n",
       "  'stage1_unit3_bn2_gamma': <mxnet.ndarray.NDArray at 0x81a8208>,\n",
       "  'stage1_unit3_bn3_beta': <mxnet.ndarray.NDArray at 0x81a5ba8>,\n",
       "  'stage1_unit3_bn3_gamma': <mxnet.ndarray.NDArray at 0x81bc6a0>,\n",
       "  'stage1_unit3_conv1_weight': <mxnet.ndarray.NDArray at 0x82630f0>,\n",
       "  'stage1_unit3_conv2_weight': <mxnet.ndarray.NDArray at 0x81b1748>,\n",
       "  'stage1_unit3_conv3_weight': <mxnet.ndarray.NDArray at 0x81a5f60>,\n",
       "  'stage2_unit1_bn1_beta': <mxnet.ndarray.NDArray at 0x82631d0>,\n",
       "  'stage2_unit1_bn1_gamma': <mxnet.ndarray.NDArray at 0x81a8630>,\n",
       "  'stage2_unit1_bn2_beta': <mxnet.ndarray.NDArray at 0x81bcf28>,\n",
       "  'stage2_unit1_bn2_gamma': <mxnet.ndarray.NDArray at 0x8218cf8>,\n",
       "  'stage2_unit1_bn3_beta': <mxnet.ndarray.NDArray at 0x81bca90>,\n",
       "  'stage2_unit1_bn3_gamma': <mxnet.ndarray.NDArray at 0x81b1278>,\n",
       "  'stage2_unit1_conv1_weight': <mxnet.ndarray.NDArray at 0x81a80f0>,\n",
       "  'stage2_unit1_conv2_weight': <mxnet.ndarray.NDArray at 0x81b1208>,\n",
       "  'stage2_unit1_conv3_weight': <mxnet.ndarray.NDArray at 0x81a5b38>,\n",
       "  'stage2_unit1_sc_weight': <mxnet.ndarray.NDArray at 0x8218eb8>,\n",
       "  'stage2_unit2_bn1_beta': <mxnet.ndarray.NDArray at 0x81b1dd8>,\n",
       "  'stage2_unit2_bn1_gamma': <mxnet.ndarray.NDArray at 0x81b1fd0>,\n",
       "  'stage2_unit2_bn2_beta': <mxnet.ndarray.NDArray at 0x81a8a20>,\n",
       "  'stage2_unit2_bn2_gamma': <mxnet.ndarray.NDArray at 0x81a8d30>,\n",
       "  'stage2_unit2_bn3_beta': <mxnet.ndarray.NDArray at 0x81a85f8>,\n",
       "  'stage2_unit2_bn3_gamma': <mxnet.ndarray.NDArray at 0x81bc780>,\n",
       "  'stage2_unit2_conv1_weight': <mxnet.ndarray.NDArray at 0x8263320>,\n",
       "  'stage2_unit2_conv2_weight': <mxnet.ndarray.NDArray at 0x81bc2b0>,\n",
       "  'stage2_unit2_conv3_weight': <mxnet.ndarray.NDArray at 0x81b16d8>,\n",
       "  'stage2_unit3_bn1_beta': <mxnet.ndarray.NDArray at 0x81bc470>,\n",
       "  'stage2_unit3_bn1_gamma': <mxnet.ndarray.NDArray at 0x81b10f0>,\n",
       "  'stage2_unit3_bn2_beta': <mxnet.ndarray.NDArray at 0x81a8ef0>,\n",
       "  'stage2_unit3_bn2_gamma': <mxnet.ndarray.NDArray at 0x81a8080>,\n",
       "  'stage2_unit3_bn3_beta': <mxnet.ndarray.NDArray at 0x81bc7f0>,\n",
       "  'stage2_unit3_bn3_gamma': <mxnet.ndarray.NDArray at 0x8218a90>,\n",
       "  'stage2_unit3_conv1_weight': <mxnet.ndarray.NDArray at 0x81bce80>,\n",
       "  'stage2_unit3_conv2_weight': <mxnet.ndarray.NDArray at 0x81b15f8>,\n",
       "  'stage2_unit3_conv3_weight': <mxnet.ndarray.NDArray at 0x81b1c18>,\n",
       "  'stage2_unit4_bn1_beta': <mxnet.ndarray.NDArray at 0x81bcc50>,\n",
       "  'stage2_unit4_bn1_gamma': <mxnet.ndarray.NDArray at 0x81b1358>,\n",
       "  'stage2_unit4_bn2_beta': <mxnet.ndarray.NDArray at 0x81bc710>,\n",
       "  'stage2_unit4_bn2_gamma': <mxnet.ndarray.NDArray at 0x81b12e8>,\n",
       "  'stage2_unit4_bn3_beta': <mxnet.ndarray.NDArray at 0x81a8470>,\n",
       "  'stage2_unit4_bn3_gamma': <mxnet.ndarray.NDArray at 0x81bcb70>,\n",
       "  'stage2_unit4_conv1_weight': <mxnet.ndarray.NDArray at 0x81b1b38>,\n",
       "  'stage2_unit4_conv2_weight': <mxnet.ndarray.NDArray at 0x81bc2e8>,\n",
       "  'stage2_unit4_conv3_weight': <mxnet.ndarray.NDArray at 0x81b1828>,\n",
       "  'stage3_unit1_bn1_beta': <mxnet.ndarray.NDArray at 0x81a89e8>,\n",
       "  'stage3_unit1_bn1_gamma': <mxnet.ndarray.NDArray at 0x81b11d0>,\n",
       "  'stage3_unit1_bn2_beta': <mxnet.ndarray.NDArray at 0x8263080>,\n",
       "  'stage3_unit1_bn2_gamma': <mxnet.ndarray.NDArray at 0x8263160>,\n",
       "  'stage3_unit1_bn3_beta': <mxnet.ndarray.NDArray at 0x81bccc0>,\n",
       "  'stage3_unit1_bn3_gamma': <mxnet.ndarray.NDArray at 0x81bc208>,\n",
       "  'stage3_unit1_conv1_weight': <mxnet.ndarray.NDArray at 0x81bc588>,\n",
       "  'stage3_unit1_conv2_weight': <mxnet.ndarray.NDArray at 0x81a80b8>,\n",
       "  'stage3_unit1_conv3_weight': <mxnet.ndarray.NDArray at 0x81bc550>,\n",
       "  'stage3_unit1_sc_weight': <mxnet.ndarray.NDArray at 0x81bce10>,\n",
       "  'stage3_unit2_bn1_beta': <mxnet.ndarray.NDArray at 0x81a8390>,\n",
       "  'stage3_unit2_bn1_gamma': <mxnet.ndarray.NDArray at 0x81b1cc0>,\n",
       "  'stage3_unit2_bn2_beta': <mxnet.ndarray.NDArray at 0x81a8b70>,\n",
       "  'stage3_unit2_bn2_gamma': <mxnet.ndarray.NDArray at 0x81b1d30>,\n",
       "  'stage3_unit2_bn3_beta': <mxnet.ndarray.NDArray at 0x81bcc88>,\n",
       "  'stage3_unit2_bn3_gamma': <mxnet.ndarray.NDArray at 0x81bc668>,\n",
       "  'stage3_unit2_conv1_weight': <mxnet.ndarray.NDArray at 0x81a8400>,\n",
       "  'stage3_unit2_conv2_weight': <mxnet.ndarray.NDArray at 0x81b1be0>,\n",
       "  'stage3_unit2_conv3_weight': <mxnet.ndarray.NDArray at 0x81b1898>,\n",
       "  'stage3_unit3_bn1_beta': <mxnet.ndarray.NDArray at 0x8263278>,\n",
       "  'stage3_unit3_bn1_gamma': <mxnet.ndarray.NDArray at 0x81a8550>,\n",
       "  'stage3_unit3_bn2_beta': <mxnet.ndarray.NDArray at 0x81b1940>,\n",
       "  'stage3_unit3_bn2_gamma': <mxnet.ndarray.NDArray at 0x81bc9b0>,\n",
       "  'stage3_unit3_bn3_beta': <mxnet.ndarray.NDArray at 0x81bc7b8>,\n",
       "  'stage3_unit3_bn3_gamma': <mxnet.ndarray.NDArray at 0x81a8b00>,\n",
       "  'stage3_unit3_conv1_weight': <mxnet.ndarray.NDArray at 0x81a84e0>,\n",
       "  'stage3_unit3_conv2_weight': <mxnet.ndarray.NDArray at 0x82632b0>,\n",
       "  'stage3_unit3_conv3_weight': <mxnet.ndarray.NDArray at 0x8218898>,\n",
       "  'stage3_unit4_bn1_beta': <mxnet.ndarray.NDArray at 0x8263470>,\n",
       "  'stage3_unit4_bn1_gamma': <mxnet.ndarray.NDArray at 0x81a82b0>,\n",
       "  'stage3_unit4_bn2_beta': <mxnet.ndarray.NDArray at 0x81b19e8>,\n",
       "  'stage3_unit4_bn2_gamma': <mxnet.ndarray.NDArray at 0x81a8278>,\n",
       "  'stage3_unit4_bn3_beta': <mxnet.ndarray.NDArray at 0x81a8cf8>,\n",
       "  'stage3_unit4_bn3_gamma': <mxnet.ndarray.NDArray at 0x81bc630>,\n",
       "  'stage3_unit4_conv1_weight': <mxnet.ndarray.NDArray at 0x81a8e80>,\n",
       "  'stage3_unit4_conv2_weight': <mxnet.ndarray.NDArray at 0x81a8668>,\n",
       "  'stage3_unit4_conv3_weight': <mxnet.ndarray.NDArray at 0x81b1f98>,\n",
       "  'stage3_unit5_bn1_beta': <mxnet.ndarray.NDArray at 0x81a5be0>,\n",
       "  'stage3_unit5_bn1_gamma': <mxnet.ndarray.NDArray at 0x81a5fd0>,\n",
       "  'stage3_unit5_bn2_beta': <mxnet.ndarray.NDArray at 0x81b1390>,\n",
       "  'stage3_unit5_bn2_gamma': <mxnet.ndarray.NDArray at 0x8263390>,\n",
       "  'stage3_unit5_bn3_beta': <mxnet.ndarray.NDArray at 0x81bcac8>,\n",
       "  'stage3_unit5_bn3_gamma': <mxnet.ndarray.NDArray at 0x81bc8d0>,\n",
       "  'stage3_unit5_conv1_weight': <mxnet.ndarray.NDArray at 0x81b1d68>,\n",
       "  'stage3_unit5_conv2_weight': <mxnet.ndarray.NDArray at 0x81bc160>,\n",
       "  'stage3_unit5_conv3_weight': <mxnet.ndarray.NDArray at 0x81b12b0>,\n",
       "  'stage3_unit6_bn1_beta': <mxnet.ndarray.NDArray at 0x81a8e48>,\n",
       "  'stage3_unit6_bn1_gamma': <mxnet.ndarray.NDArray at 0x81a8518>,\n",
       "  'stage3_unit6_bn2_beta': <mxnet.ndarray.NDArray at 0x81b1240>,\n",
       "  'stage3_unit6_bn2_gamma': <mxnet.ndarray.NDArray at 0x81bcf60>,\n",
       "  'stage3_unit6_bn3_beta': <mxnet.ndarray.NDArray at 0x81a5f28>,\n",
       "  'stage3_unit6_bn3_gamma': <mxnet.ndarray.NDArray at 0x81bc4a8>,\n",
       "  'stage3_unit6_conv1_weight': <mxnet.ndarray.NDArray at 0x81b15c0>,\n",
       "  'stage3_unit6_conv2_weight': <mxnet.ndarray.NDArray at 0x81bccf8>,\n",
       "  'stage3_unit6_conv3_weight': <mxnet.ndarray.NDArray at 0x82185c0>,\n",
       "  'stage4_unit1_bn1_beta': <mxnet.ndarray.NDArray at 0x81a8eb8>,\n",
       "  'stage4_unit1_bn1_gamma': <mxnet.ndarray.NDArray at 0x81a87b8>,\n",
       "  'stage4_unit1_bn2_beta': <mxnet.ndarray.NDArray at 0x82187b8>,\n",
       "  'stage4_unit1_bn2_gamma': <mxnet.ndarray.NDArray at 0x8263128>,\n",
       "  'stage4_unit1_bn3_beta': <mxnet.ndarray.NDArray at 0x81bcef0>,\n",
       "  'stage4_unit1_bn3_gamma': <mxnet.ndarray.NDArray at 0x81b1048>,\n",
       "  'stage4_unit1_conv1_weight': <mxnet.ndarray.NDArray at 0x81b1e10>,\n",
       "  'stage4_unit1_conv2_weight': <mxnet.ndarray.NDArray at 0x81a8978>,\n",
       "  'stage4_unit1_conv3_weight': <mxnet.ndarray.NDArray at 0x81a84a8>,\n",
       "  'stage4_unit1_sc_weight': <mxnet.ndarray.NDArray at 0x81bcba8>,\n",
       "  'stage4_unit2_bn1_beta': <mxnet.ndarray.NDArray at 0x81a5e48>,\n",
       "  'stage4_unit2_bn1_gamma': <mxnet.ndarray.NDArray at 0x81bca58>,\n",
       "  'stage4_unit2_bn2_beta': <mxnet.ndarray.NDArray at 0x81a87f0>,\n",
       "  'stage4_unit2_bn2_gamma': <mxnet.ndarray.NDArray at 0x81a89b0>,\n",
       "  'stage4_unit2_bn3_beta': <mxnet.ndarray.NDArray at 0x81a8860>,\n",
       "  'stage4_unit2_bn3_gamma': <mxnet.ndarray.NDArray at 0x81a8320>,\n",
       "  'stage4_unit2_conv1_weight': <mxnet.ndarray.NDArray at 0x81a5da0>,\n",
       "  'stage4_unit2_conv2_weight': <mxnet.ndarray.NDArray at 0x81bc390>,\n",
       "  'stage4_unit2_conv3_weight': <mxnet.ndarray.NDArray at 0x81bca20>,\n",
       "  'stage4_unit3_bn1_beta': <mxnet.ndarray.NDArray at 0x81bc828>,\n",
       "  'stage4_unit3_bn1_gamma': <mxnet.ndarray.NDArray at 0x81b17f0>,\n",
       "  'stage4_unit3_bn2_beta': <mxnet.ndarray.NDArray at 0x8218860>,\n",
       "  'stage4_unit3_bn2_gamma': <mxnet.ndarray.NDArray at 0x81b1470>,\n",
       "  'stage4_unit3_bn3_beta': <mxnet.ndarray.NDArray at 0x81b1ba8>,\n",
       "  'stage4_unit3_bn3_gamma': <mxnet.ndarray.NDArray at 0x81a8908>,\n",
       "  'stage4_unit3_conv1_weight': <mxnet.ndarray.NDArray at 0x81b1e80>,\n",
       "  'stage4_unit3_conv2_weight': <mxnet.ndarray.NDArray at 0x81bcda0>,\n",
       "  'stage4_unit3_conv3_weight': <mxnet.ndarray.NDArray at 0x81bc1d0>},\n",
       " {'bn0_moving_mean': <mxnet.ndarray.NDArray at 0x81a5c50>,\n",
       "  'bn0_moving_var': <mxnet.ndarray.NDArray at 0x81bc0b8>,\n",
       "  'bn1_moving_mean': <mxnet.ndarray.NDArray at 0x81a8780>,\n",
       "  'bn1_moving_var': <mxnet.ndarray.NDArray at 0x81a8cc0>,\n",
       "  'bn_data_moving_mean': <mxnet.ndarray.NDArray at 0x81a8c18>,\n",
       "  'bn_data_moving_var': <mxnet.ndarray.NDArray at 0x81a81d0>,\n",
       "  'stage1_unit1_bn1_moving_mean': <mxnet.ndarray.NDArray at 0x81a8828>,\n",
       "  'stage1_unit1_bn1_moving_var': <mxnet.ndarray.NDArray at 0x81a8da0>,\n",
       "  'stage1_unit1_bn2_moving_mean': <mxnet.ndarray.NDArray at 0x81bcf98>,\n",
       "  'stage1_unit1_bn2_moving_var': <mxnet.ndarray.NDArray at 0x81b1a58>,\n",
       "  'stage1_unit1_bn3_moving_mean': <mxnet.ndarray.NDArray at 0x81bc908>,\n",
       "  'stage1_unit1_bn3_moving_var': <mxnet.ndarray.NDArray at 0x81b1550>,\n",
       "  'stage1_unit2_bn1_moving_mean': <mxnet.ndarray.NDArray at 0x81b1588>,\n",
       "  'stage1_unit2_bn1_moving_var': <mxnet.ndarray.NDArray at 0x81bc5f8>,\n",
       "  'stage1_unit2_bn2_moving_mean': <mxnet.ndarray.NDArray at 0x81b1198>,\n",
       "  'stage1_unit2_bn2_moving_var': <mxnet.ndarray.NDArray at 0x81a5b70>,\n",
       "  'stage1_unit2_bn3_moving_mean': <mxnet.ndarray.NDArray at 0x81b1ac8>,\n",
       "  'stage1_unit2_bn3_moving_var': <mxnet.ndarray.NDArray at 0x81a8c50>,\n",
       "  'stage1_unit3_bn1_moving_mean': <mxnet.ndarray.NDArray at 0x81a5dd8>,\n",
       "  'stage1_unit3_bn1_moving_var': <mxnet.ndarray.NDArray at 0x81a8128>,\n",
       "  'stage1_unit3_bn2_moving_mean': <mxnet.ndarray.NDArray at 0x81b1e48>,\n",
       "  'stage1_unit3_bn2_moving_var': <mxnet.ndarray.NDArray at 0x81bc438>,\n",
       "  'stage1_unit3_bn3_moving_mean': <mxnet.ndarray.NDArray at 0x81a82e8>,\n",
       "  'stage1_unit3_bn3_moving_var': <mxnet.ndarray.NDArray at 0x81a85c0>,\n",
       "  'stage2_unit1_bn1_moving_mean': <mxnet.ndarray.NDArray at 0x81b14e0>,\n",
       "  'stage2_unit1_bn1_moving_var': <mxnet.ndarray.NDArray at 0x81a8b38>,\n",
       "  'stage2_unit1_bn2_moving_mean': <mxnet.ndarray.NDArray at 0x8263048>,\n",
       "  'stage2_unit1_bn2_moving_var': <mxnet.ndarray.NDArray at 0x82632e8>,\n",
       "  'stage2_unit1_bn3_moving_mean': <mxnet.ndarray.NDArray at 0x81b1780>,\n",
       "  'stage2_unit1_bn3_moving_var': <mxnet.ndarray.NDArray at 0x82633c8>,\n",
       "  'stage2_unit2_bn1_moving_mean': <mxnet.ndarray.NDArray at 0x81bcc18>,\n",
       "  'stage2_unit2_bn1_moving_var': <mxnet.ndarray.NDArray at 0x81bcbe0>,\n",
       "  'stage2_unit2_bn2_moving_mean': <mxnet.ndarray.NDArray at 0x81b1668>,\n",
       "  'stage2_unit2_bn2_moving_var': <mxnet.ndarray.NDArray at 0x81b1080>,\n",
       "  'stage2_unit2_bn3_moving_mean': <mxnet.ndarray.NDArray at 0x8263208>,\n",
       "  'stage2_unit2_bn3_moving_var': <mxnet.ndarray.NDArray at 0x81bc518>,\n",
       "  'stage2_unit3_bn1_moving_mean': <mxnet.ndarray.NDArray at 0x81b17b8>,\n",
       "  'stage2_unit3_bn1_moving_var': <mxnet.ndarray.NDArray at 0x81b1a20>,\n",
       "  'stage2_unit3_bn2_moving_mean': <mxnet.ndarray.NDArray at 0x81a5f98>,\n",
       "  'stage2_unit3_bn2_moving_var': <mxnet.ndarray.NDArray at 0x81bc978>,\n",
       "  'stage2_unit3_bn3_moving_mean': <mxnet.ndarray.NDArray at 0x81b1b70>,\n",
       "  'stage2_unit3_bn3_moving_var': <mxnet.ndarray.NDArray at 0x81a8898>,\n",
       "  'stage2_unit4_bn1_moving_mean': <mxnet.ndarray.NDArray at 0x81bce48>,\n",
       "  'stage2_unit4_bn1_moving_var': <mxnet.ndarray.NDArray at 0x81b1438>,\n",
       "  'stage2_unit4_bn2_moving_mean': <mxnet.ndarray.NDArray at 0x81b1518>,\n",
       "  'stage2_unit4_bn2_moving_var': <mxnet.ndarray.NDArray at 0x81bc6d8>,\n",
       "  'stage2_unit4_bn3_moving_mean': <mxnet.ndarray.NDArray at 0x81b1978>,\n",
       "  'stage2_unit4_bn3_moving_var': <mxnet.ndarray.NDArray at 0x81b1908>,\n",
       "  'stage3_unit1_bn1_moving_mean': <mxnet.ndarray.NDArray at 0x81a8438>,\n",
       "  'stage3_unit1_bn1_moving_var': <mxnet.ndarray.NDArray at 0x81bcd30>,\n",
       "  'stage3_unit1_bn2_moving_mean': <mxnet.ndarray.NDArray at 0x81a8ac8>,\n",
       "  'stage3_unit1_bn2_moving_var': <mxnet.ndarray.NDArray at 0x81a8358>,\n",
       "  'stage3_unit1_bn3_moving_mean': <mxnet.ndarray.NDArray at 0x81a5eb8>,\n",
       "  'stage3_unit1_bn3_moving_var': <mxnet.ndarray.NDArray at 0x81a86a0>,\n",
       "  'stage3_unit2_bn1_moving_mean': <mxnet.ndarray.NDArray at 0x81bc3c8>,\n",
       "  'stage3_unit2_bn1_moving_var': <mxnet.ndarray.NDArray at 0x81a8588>,\n",
       "  'stage3_unit2_bn2_moving_mean': <mxnet.ndarray.NDArray at 0x81a5e80>,\n",
       "  'stage3_unit2_bn2_moving_var': <mxnet.ndarray.NDArray at 0x81a5cc0>,\n",
       "  'stage3_unit2_bn3_moving_mean': <mxnet.ndarray.NDArray at 0x81b16a0>,\n",
       "  'stage3_unit2_bn3_moving_var': <mxnet.ndarray.NDArray at 0x81a8240>,\n",
       "  'stage3_unit3_bn1_moving_mean': <mxnet.ndarray.NDArray at 0x81bc9e8>,\n",
       "  'stage3_unit3_bn1_moving_var': <mxnet.ndarray.NDArray at 0x81b13c8>,\n",
       "  'stage3_unit3_bn2_moving_mean': <mxnet.ndarray.NDArray at 0x81b10b8>,\n",
       "  'stage3_unit3_bn2_moving_var': <mxnet.ndarray.NDArray at 0x81bc898>,\n",
       "  'stage3_unit3_bn3_moving_mean': <mxnet.ndarray.NDArray at 0x81b1eb8>,\n",
       "  'stage3_unit3_bn3_moving_var': <mxnet.ndarray.NDArray at 0x81a8f98>,\n",
       "  'stage3_unit4_bn1_moving_mean': <mxnet.ndarray.NDArray at 0x81b1da0>,\n",
       "  'stage3_unit4_bn1_moving_var': <mxnet.ndarray.NDArray at 0x81a8710>,\n",
       "  'stage3_unit4_bn2_moving_mean': <mxnet.ndarray.NDArray at 0x81bc4e0>,\n",
       "  'stage3_unit4_bn2_moving_var': <mxnet.ndarray.NDArray at 0x81bcdd8>,\n",
       "  'stage3_unit4_bn3_moving_mean': <mxnet.ndarray.NDArray at 0x81b1c50>,\n",
       "  'stage3_unit4_bn3_moving_var': <mxnet.ndarray.NDArray at 0x81bc198>,\n",
       "  'stage3_unit5_bn1_moving_mean': <mxnet.ndarray.NDArray at 0x81b1f60>,\n",
       "  'stage3_unit5_bn1_moving_var': <mxnet.ndarray.NDArray at 0x81b1710>,\n",
       "  'stage3_unit5_bn2_moving_mean': <mxnet.ndarray.NDArray at 0x81bceb8>,\n",
       "  'stage3_unit5_bn2_moving_var': <mxnet.ndarray.NDArray at 0x81bc358>,\n",
       "  'stage3_unit5_bn3_moving_mean': <mxnet.ndarray.NDArray at 0x81a5cf8>,\n",
       "  'stage3_unit5_bn3_moving_var': <mxnet.ndarray.NDArray at 0x81a8048>,\n",
       "  'stage3_unit6_bn1_moving_mean': <mxnet.ndarray.NDArray at 0x81a5c88>,\n",
       "  'stage3_unit6_bn1_moving_var': <mxnet.ndarray.NDArray at 0x81b18d0>,\n",
       "  'stage3_unit6_bn2_moving_mean': <mxnet.ndarray.NDArray at 0x81b1320>,\n",
       "  'stage3_unit6_bn2_moving_var': <mxnet.ndarray.NDArray at 0x81a8dd8>,\n",
       "  'stage3_unit6_bn3_moving_mean': <mxnet.ndarray.NDArray at 0x8218b38>,\n",
       "  'stage3_unit6_bn3_moving_var': <mxnet.ndarray.NDArray at 0x81bc400>,\n",
       "  'stage4_unit1_bn1_moving_mean': <mxnet.ndarray.NDArray at 0x81bc128>,\n",
       "  'stage4_unit1_bn1_moving_var': <mxnet.ndarray.NDArray at 0x81bcd68>,\n",
       "  'stage4_unit1_bn2_moving_mean': <mxnet.ndarray.NDArray at 0x81bc940>,\n",
       "  'stage4_unit1_bn2_moving_var': <mxnet.ndarray.NDArray at 0x81a5ef0>,\n",
       "  'stage4_unit1_bn3_moving_mean': <mxnet.ndarray.NDArray at 0x8263400>,\n",
       "  'stage4_unit1_bn3_moving_var': <mxnet.ndarray.NDArray at 0x81b1860>,\n",
       "  'stage4_unit2_bn1_moving_mean': <mxnet.ndarray.NDArray at 0x81a8d68>,\n",
       "  'stage4_unit2_bn1_moving_var': <mxnet.ndarray.NDArray at 0x81bc860>,\n",
       "  'stage4_unit2_bn2_moving_mean': <mxnet.ndarray.NDArray at 0x81a8fd0>,\n",
       "  'stage4_unit2_bn2_moving_var': <mxnet.ndarray.NDArray at 0x81a8e10>,\n",
       "  'stage4_unit2_bn3_moving_mean': <mxnet.ndarray.NDArray at 0x81a8a90>,\n",
       "  'stage4_unit2_bn3_moving_var': <mxnet.ndarray.NDArray at 0x81a8f60>,\n",
       "  'stage4_unit3_bn1_moving_mean': <mxnet.ndarray.NDArray at 0x81b1b00>,\n",
       "  'stage4_unit3_bn1_moving_var': <mxnet.ndarray.NDArray at 0x81b1630>,\n",
       "  'stage4_unit3_bn2_moving_mean': <mxnet.ndarray.NDArray at 0x81a5e10>,\n",
       "  'stage4_unit3_bn2_moving_var': <mxnet.ndarray.NDArray at 0x81a8a58>,\n",
       "  'stage4_unit3_bn3_moving_mean': <mxnet.ndarray.NDArray at 0x82187f0>,\n",
       "  'stage4_unit3_bn3_moving_var': <mxnet.ndarray.NDArray at 0x81b1400>})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mx.model.load_checkpoint('resnet-50',0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "\n",
    "We first define a function which replaces the the last fully-connected layer for a given network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_fine_tune_model(symbol, arg_params, num_classes, layer_name='flatten0'):\n",
    "    \"\"\"\n",
    "    symbol: the pre-trained network symbol\n",
    "    arg_params: the argument parameters of the pre-trained model\n",
    "    num_classes: the number of classes for the fine-tune datasets\n",
    "    layer_name: the layer name before the last fully-connected layer\n",
    "    \"\"\"\n",
    "    all_layers = sym.get_internals()\n",
    "    net = all_layers[layer_name+'_output']\n",
    "    net = mx.symbol.FullyConnected(data=net, num_hidden=num_classes, name='fc1')\n",
    "    net = mx.symbol.SoftmaxOutput(data=net, name='softmax')\n",
    "    new_args = dict({k:arg_params[k] for k in arg_params if 'fc1' not in k})\n",
    "    return (net, new_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a module. We first call `init_params` to randomly initialize parameters, next use `set_params` to replace all parameters except for the last fully-connected layer with pre-trained model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "head = '%(asctime)-15s %(message)s'\n",
    "logging.basicConfig(level=logging.DEBUG, format=head)\n",
    "\n",
    "def fit(symbol, arg_params, aux_params, train, val, batch_size, num_gpus):\n",
    "    devs = [mx.gpu(i) for i in range(num_gpus)]\n",
    "    mod = mx.mod.Module(symbol=new_sym, context=devs)\n",
    "    mod.bind(data_shapes=train.provide_data, label_shapes=train.provide_label)\n",
    "    mod.init_params(initializer=mx.init.Xavier(rnd_type='gaussian', factor_type=\"in\", magnitude=2))\n",
    "    mod.set_params(new_args, aux_params, allow_missing=True)\n",
    "    mod.fit(train, val, \n",
    "        num_epoch=8,\n",
    "        batch_end_callback = mx.callback.Speedometer(batch_size, 10),        \n",
    "        kvstore='device',\n",
    "        optimizer='sgd',\n",
    "        optimizer_params={'learning_rate':0.01},\n",
    "        eval_metric='acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can start training. We use AWS EC2 g2.8xlarge, which has 8 GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "MXNetError",
     "evalue": "[19:06:10] D:\\chhong\\mxnet\\src\\storage\\storage.cc:44: Please compile with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMXNetError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-cee8efecb537>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_per_gpu\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnum_gpus\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_iterators\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_sym\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maux_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_gpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-ead463acb518>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(symbol, arg_params, aux_params, train, val, batch_size, num_gpus)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdevs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_gpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msymbol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnew_sym\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mmod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprovide_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprovide_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mmod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minitializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXavier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrnd_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gaussian'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfactor_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"in\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmagnitude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mmod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maux_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda2\\lib\\site-packages\\mxnet-0.7.0-py2.7.egg\\mxnet\\module\\module.pyc\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, data_shapes, label_shapes, for_training, inputs_need_grad, force_rebind, shared_module)\u001b[0m\n\u001b[1;32m    254\u001b[0m                                                      \u001b[0mlabel_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_param_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m                                                      \u001b[0mfor_training\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs_need_grad\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m                                                      shared_group, logger=self.logger)\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mshared_module\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda2\\lib\\site-packages\\mxnet-0.7.0-py2.7.egg\\mxnet\\module\\executor_group.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, symbol, contexts, workload, data_shapes, label_shapes, param_names, for_training, inputs_need_grad, shared_group, input_types, logger)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[1;31m# calculate workload and bind executors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecide_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_shapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind_exec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshared_group\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecide_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_shapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda2\\lib\\site-packages\\mxnet-0.7.0-py2.7.egg\\mxnet\\module\\executor_group.pyc\u001b[0m in \u001b[0;36mbind_exec\u001b[0;34m(self, data_shapes, label_shapes, shared_group)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontexts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_bind_ith_exec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshared_group\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[1;31m# convenient data structures\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda2\\lib\\site-packages\\mxnet-0.7.0-py2.7.egg\\mxnet\\module\\executor_group.pyc\u001b[0m in \u001b[0;36m_bind_ith_exec\u001b[0;34m(self, i, data_shapes, label_shapes, shared_group)\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# data or label\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m                 arg_arr = _get_or_reshape(name, shared_data_arrays, arg_shapes[j], arg_types[j],\n\u001b[0;32m--> 391\u001b[0;31m                                           context, self.logger)\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m                 \u001b[1;31m# data might also need grad if inputs_need_grad is True\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda2\\lib\\site-packages\\mxnet-0.7.0-py2.7.egg\\mxnet\\module\\executor_group.pyc\u001b[0m in \u001b[0;36m_get_or_reshape\u001b[0;34m(name, shared_data_arrays, arg_shape, arg_type, context, logger)\u001b[0m\n\u001b[1;32m    367\u001b[0m                     \u001b[0mshared_data_arrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m                 \u001b[0marg_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m                 \u001b[0mshared_data_arrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda2\\lib\\site-packages\\mxnet-0.7.0-py2.7.egg\\mxnet\\ndarray.pyc\u001b[0m in \u001b[0;36mzeros\u001b[0;34m(shape, ctx, dtype)\u001b[0m\n\u001b[1;32m    686\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mcreated\u001b[0m \u001b[0mNDArray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \"\"\"\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m     \u001b[0marr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda2\\lib\\site-packages\\mxnet-0.7.0-py2.7.egg\\mxnet\\ndarray.pyc\u001b[0m in \u001b[0;36mempty\u001b[0;34m(shape, ctx, dtype)\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mctx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m         \u001b[0mctx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault_ctx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m     \u001b[1;32mreturn\u001b[0m \u001b[0mNDArray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_new_alloc_handle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlhs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrhs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda2\\lib\\site-packages\\mxnet-0.7.0-py2.7.egg\\mxnet\\ndarray.pyc\u001b[0m in \u001b[0;36m_new_alloc_handle\u001b[0;34m(shape, ctx, delay_alloc, dtype)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelay_alloc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_DTYPE_NP_TO_MX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         ctypes.byref(hdl)))\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mhdl\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda2\\lib\\site-packages\\mxnet-0.7.0-py2.7.egg\\mxnet\\base.pyc\u001b[0m in \u001b[0;36mcheck_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \"\"\"\n\u001b[1;32m     76\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[1;32mraise\u001b[0m \u001b[0mMXNetError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMXGetLastError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mc_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMXNetError\u001b[0m: [19:06:10] D:\\chhong\\mxnet\\src\\storage\\storage.cc:44: Please compile with CUDA enabled"
     ]
    }
   ],
   "source": [
    "num_classes = 256\n",
    "batch_per_gpu = 16\n",
    "num_gpus = 8\n",
    "\n",
    "(new_sym, new_args) = get_fine_tune_model(sym, arg_params, num_classes)\n",
    "\n",
    "batch_size = batch_per_gpu * num_gpus\n",
    "(train, val) = get_iterators(batch_size)\n",
    "fit(new_sym, new_args, aux_params, train, val, batch_size, num_gpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "As can be seen, even for 8 data epochs, we can get 78% validation accuracy. It matches the state-of-the-art results training on caltech-256 alone, e.g. [VGG](http://www.robots.ox.ac.uk/~vgg/research/deep_eval/). \n",
    "\n",
    "Next we try to use another pretrained model. It uses the complete Imagenet dataset, which is 10x larger than the Imagenet 1K classes one, and is trained with a 3x deeper Resnet network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-10-22 18:35:42,274 Already binded, ignoring bind()\n",
      "2016-10-22 18:35:55,659 Epoch[0] Batch [10]\tSpeed: 139.63 samples/sec\tTrain-accuracy=0.070312\n",
      "2016-10-22 18:36:04,814 Epoch[0] Batch [20]\tSpeed: 139.83 samples/sec\tTrain-accuracy=0.349219\n",
      "2016-10-22 18:36:13,991 Epoch[0] Batch [30]\tSpeed: 139.49 samples/sec\tTrain-accuracy=0.585156\n",
      "2016-10-22 18:36:23,163 Epoch[0] Batch [40]\tSpeed: 139.57 samples/sec\tTrain-accuracy=0.642188\n",
      "2016-10-22 18:36:32,309 Epoch[0] Batch [50]\tSpeed: 139.97 samples/sec\tTrain-accuracy=0.728906\n",
      "2016-10-22 18:36:41,426 Epoch[0] Batch [60]\tSpeed: 140.41 samples/sec\tTrain-accuracy=0.760156\n",
      "2016-10-22 18:36:50,531 Epoch[0] Batch [70]\tSpeed: 140.60 samples/sec\tTrain-accuracy=0.778906\n",
      "2016-10-22 18:36:59,631 Epoch[0] Batch [80]\tSpeed: 140.68 samples/sec\tTrain-accuracy=0.786719\n",
      "2016-10-22 18:37:08,742 Epoch[0] Batch [90]\tSpeed: 140.51 samples/sec\tTrain-accuracy=0.797656\n",
      "2016-10-22 18:37:17,857 Epoch[0] Batch [100]\tSpeed: 140.45 samples/sec\tTrain-accuracy=0.823438\n",
      "2016-10-22 18:37:26,969 Epoch[0] Batch [110]\tSpeed: 140.50 samples/sec\tTrain-accuracy=0.827344\n",
      "2016-10-22 18:37:36,094 Epoch[0] Batch [120]\tSpeed: 140.29 samples/sec\tTrain-accuracy=0.829688\n",
      "2016-10-22 18:37:36,095 Epoch[0] Train-accuracy=nan\n",
      "2016-10-22 18:37:36,096 Epoch[0] Time cost=113.804\n",
      "2016-10-22 18:38:08,728 Epoch[0] Validation-accuracy=0.829780\n",
      "2016-10-22 18:38:18,228 Epoch[1] Batch [10]\tSpeed: 139.92 samples/sec\tTrain-accuracy=0.862926\n",
      "2016-10-22 18:38:27,365 Epoch[1] Batch [20]\tSpeed: 140.10 samples/sec\tTrain-accuracy=0.867969\n",
      "2016-10-22 18:38:36,476 Epoch[1] Batch [30]\tSpeed: 140.52 samples/sec\tTrain-accuracy=0.884375\n",
      "2016-10-22 18:38:45,581 Epoch[1] Batch [40]\tSpeed: 140.60 samples/sec\tTrain-accuracy=0.856250\n",
      "2016-10-22 18:38:54,671 Epoch[1] Batch [50]\tSpeed: 140.84 samples/sec\tTrain-accuracy=0.888281\n",
      "2016-10-22 18:39:03,774 Epoch[1] Batch [60]\tSpeed: 140.62 samples/sec\tTrain-accuracy=0.891406\n",
      "2016-10-22 18:39:12,893 Epoch[1] Batch [70]\tSpeed: 140.38 samples/sec\tTrain-accuracy=0.893750\n",
      "2016-10-22 18:39:22,016 Epoch[1] Batch [80]\tSpeed: 140.33 samples/sec\tTrain-accuracy=0.911719\n",
      "2016-10-22 18:39:31,173 Epoch[1] Batch [90]\tSpeed: 139.79 samples/sec\tTrain-accuracy=0.893750\n",
      "2016-10-22 18:39:40,341 Epoch[1] Batch [100]\tSpeed: 139.65 samples/sec\tTrain-accuracy=0.885938\n",
      "2016-10-22 18:39:49,522 Epoch[1] Batch [110]\tSpeed: 139.45 samples/sec\tTrain-accuracy=0.901563\n",
      "2016-10-22 18:39:57,750 Epoch[1] Train-accuracy=0.907986\n",
      "2016-10-22 18:39:57,751 Epoch[1] Time cost=109.022\n",
      "2016-10-22 18:40:30,649 Epoch[1] Validation-accuracy=0.848608\n",
      "2016-10-22 18:40:40,134 Epoch[2] Batch [10]\tSpeed: 140.33 samples/sec\tTrain-accuracy=0.921875\n",
      "2016-10-22 18:40:49,247 Epoch[2] Batch [20]\tSpeed: 140.47 samples/sec\tTrain-accuracy=0.911719\n",
      "2016-10-22 18:40:58,367 Epoch[2] Batch [30]\tSpeed: 140.37 samples/sec\tTrain-accuracy=0.914844\n",
      "2016-10-22 18:41:07,515 Epoch[2] Batch [40]\tSpeed: 139.93 samples/sec\tTrain-accuracy=0.913281\n",
      "2016-10-22 18:41:16,659 Epoch[2] Batch [50]\tSpeed: 140.01 samples/sec\tTrain-accuracy=0.929688\n",
      "2016-10-22 18:41:25,826 Epoch[2] Batch [60]\tSpeed: 139.64 samples/sec\tTrain-accuracy=0.940625\n",
      "2016-10-22 18:41:35,015 Epoch[2] Batch [70]\tSpeed: 139.31 samples/sec\tTrain-accuracy=0.927344\n",
      "2016-10-22 18:41:44,178 Epoch[2] Batch [80]\tSpeed: 139.72 samples/sec\tTrain-accuracy=0.940625\n",
      "2016-10-22 18:41:53,316 Epoch[2] Batch [90]\tSpeed: 140.09 samples/sec\tTrain-accuracy=0.928125\n",
      "2016-10-22 18:42:02,413 Epoch[2] Batch [100]\tSpeed: 140.72 samples/sec\tTrain-accuracy=0.948438\n",
      "2016-10-22 18:42:11,522 Epoch[2] Batch [110]\tSpeed: 140.53 samples/sec\tTrain-accuracy=0.925781\n",
      "2016-10-22 18:42:20,624 Epoch[2] Batch [120]\tSpeed: 140.66 samples/sec\tTrain-accuracy=0.928906\n",
      "2016-10-22 18:42:20,625 Epoch[2] Train-accuracy=nan\n",
      "2016-10-22 18:42:20,626 Epoch[2] Time cost=109.976\n",
      "2016-10-22 18:42:53,414 Epoch[2] Validation-accuracy=0.853269\n",
      "2016-10-22 18:43:02,925 Epoch[3] Batch [10]\tSpeed: 139.86 samples/sec\tTrain-accuracy=0.941051\n",
      "2016-10-22 18:43:12,095 Epoch[3] Batch [20]\tSpeed: 139.60 samples/sec\tTrain-accuracy=0.935156\n",
      "2016-10-22 18:43:21,270 Epoch[3] Batch [30]\tSpeed: 139.52 samples/sec\tTrain-accuracy=0.939844\n",
      "2016-10-22 18:43:30,434 Epoch[3] Batch [40]\tSpeed: 139.70 samples/sec\tTrain-accuracy=0.945312\n",
      "2016-10-22 18:43:39,557 Epoch[3] Batch [50]\tSpeed: 140.31 samples/sec\tTrain-accuracy=0.946094\n",
      "2016-10-22 18:43:48,680 Epoch[3] Batch [60]\tSpeed: 140.33 samples/sec\tTrain-accuracy=0.937500\n",
      "2016-10-22 18:43:57,775 Epoch[3] Batch [70]\tSpeed: 140.75 samples/sec\tTrain-accuracy=0.951562\n",
      "2016-10-22 18:44:06,899 Epoch[3] Batch [80]\tSpeed: 140.31 samples/sec\tTrain-accuracy=0.956250\n",
      "2016-10-22 18:44:16,000 Epoch[3] Batch [90]\tSpeed: 140.67 samples/sec\tTrain-accuracy=0.942969\n",
      "2016-10-22 18:44:25,110 Epoch[3] Batch [100]\tSpeed: 140.52 samples/sec\tTrain-accuracy=0.958594\n",
      "2016-10-22 18:44:34,225 Epoch[3] Batch [110]\tSpeed: 140.46 samples/sec\tTrain-accuracy=0.946875\n",
      "2016-10-22 18:44:42,448 Epoch[3] Train-accuracy=0.952257\n",
      "2016-10-22 18:44:42,450 Epoch[3] Time cost=109.035\n",
      "2016-10-22 18:45:15,423 Epoch[3] Validation-accuracy=0.857587\n",
      "2016-10-22 18:45:24,921 Epoch[4] Batch [10]\tSpeed: 139.90 samples/sec\tTrain-accuracy=0.965199\n",
      "2016-10-22 18:45:34,041 Epoch[4] Batch [20]\tSpeed: 140.37 samples/sec\tTrain-accuracy=0.964844\n",
      "2016-10-22 18:45:43,172 Epoch[4] Batch [30]\tSpeed: 140.20 samples/sec\tTrain-accuracy=0.968750\n",
      "2016-10-22 18:45:52,287 Epoch[4] Batch [40]\tSpeed: 140.45 samples/sec\tTrain-accuracy=0.955469\n",
      "2016-10-22 18:46:01,418 Epoch[4] Batch [50]\tSpeed: 140.20 samples/sec\tTrain-accuracy=0.971094\n",
      "2016-10-22 18:46:10,534 Epoch[4] Batch [60]\tSpeed: 140.43 samples/sec\tTrain-accuracy=0.954688\n",
      "2016-10-22 18:46:19,664 Epoch[4] Batch [70]\tSpeed: 140.21 samples/sec\tTrain-accuracy=0.964063\n",
      "2016-10-22 18:46:28,811 Epoch[4] Batch [80]\tSpeed: 139.96 samples/sec\tTrain-accuracy=0.969531\n",
      "2016-10-22 18:46:37,986 Epoch[4] Batch [90]\tSpeed: 139.53 samples/sec\tTrain-accuracy=0.961719\n",
      "2016-10-22 18:46:47,150 Epoch[4] Batch [100]\tSpeed: 139.70 samples/sec\tTrain-accuracy=0.966406\n",
      "2016-10-22 18:46:56,307 Epoch[4] Batch [110]\tSpeed: 139.79 samples/sec\tTrain-accuracy=0.966406\n",
      "2016-10-22 18:47:05,456 Epoch[4] Batch [120]\tSpeed: 139.94 samples/sec\tTrain-accuracy=0.966406\n",
      "2016-10-22 18:47:05,457 Epoch[4] Train-accuracy=nan\n",
      "2016-10-22 18:47:05,457 Epoch[4] Time cost=110.033\n",
      "2016-10-22 18:47:38,303 Epoch[4] Validation-accuracy=0.862329\n",
      "2016-10-22 18:47:47,779 Epoch[5] Batch [10]\tSpeed: 140.25 samples/sec\tTrain-accuracy=0.971591\n",
      "2016-10-22 18:47:56,897 Epoch[5] Batch [20]\tSpeed: 140.40 samples/sec\tTrain-accuracy=0.970313\n",
      "2016-10-22 18:48:06,006 Epoch[5] Batch [30]\tSpeed: 140.53 samples/sec\tTrain-accuracy=0.976562\n",
      "2016-10-22 18:48:15,150 Epoch[5] Batch [40]\tSpeed: 140.01 samples/sec\tTrain-accuracy=0.967187\n",
      "2016-10-22 18:48:24,320 Epoch[5] Batch [50]\tSpeed: 139.60 samples/sec\tTrain-accuracy=0.975781\n",
      "2016-10-22 18:48:33,515 Epoch[5] Batch [60]\tSpeed: 139.22 samples/sec\tTrain-accuracy=0.971094\n",
      "2016-10-22 18:48:42,707 Epoch[5] Batch [70]\tSpeed: 139.26 samples/sec\tTrain-accuracy=0.971875\n",
      "2016-10-22 18:48:51,857 Epoch[5] Batch [80]\tSpeed: 139.92 samples/sec\tTrain-accuracy=0.988281\n",
      "2016-10-22 18:49:00,980 Epoch[5] Batch [90]\tSpeed: 140.32 samples/sec\tTrain-accuracy=0.969531\n",
      "2016-10-22 18:49:10,092 Epoch[5] Batch [100]\tSpeed: 140.49 samples/sec\tTrain-accuracy=0.984375\n",
      "2016-10-22 18:49:19,205 Epoch[5] Batch [110]\tSpeed: 140.49 samples/sec\tTrain-accuracy=0.978125\n",
      "2016-10-22 18:49:27,399 Epoch[5] Train-accuracy=0.968750\n",
      "2016-10-22 18:49:27,400 Epoch[5] Time cost=109.095\n",
      "2016-10-22 18:50:00,339 Epoch[5] Validation-accuracy=0.864102\n",
      "2016-10-22 18:50:09,861 Epoch[6] Batch [10]\tSpeed: 139.72 samples/sec\tTrain-accuracy=0.978693\n",
      "2016-10-22 18:50:19,028 Epoch[6] Batch [20]\tSpeed: 139.65 samples/sec\tTrain-accuracy=0.976562\n",
      "2016-10-22 18:50:28,206 Epoch[6] Batch [30]\tSpeed: 139.48 samples/sec\tTrain-accuracy=0.975000\n",
      "2016-10-22 18:50:37,343 Epoch[6] Batch [40]\tSpeed: 140.11 samples/sec\tTrain-accuracy=0.976562\n",
      "2016-10-22 18:50:46,475 Epoch[6] Batch [50]\tSpeed: 140.18 samples/sec\tTrain-accuracy=0.971094\n",
      "2016-10-22 18:50:55,613 Epoch[6] Batch [60]\tSpeed: 140.10 samples/sec\tTrain-accuracy=0.976562\n",
      "2016-10-22 18:51:04,717 Epoch[6] Batch [70]\tSpeed: 140.60 samples/sec\tTrain-accuracy=0.978906\n",
      "2016-10-22 18:51:13,821 Epoch[6] Batch [80]\tSpeed: 140.63 samples/sec\tTrain-accuracy=0.977344\n",
      "2016-10-22 18:51:22,932 Epoch[6] Batch [90]\tSpeed: 140.50 samples/sec\tTrain-accuracy=0.971875\n",
      "2016-10-22 18:51:32,039 Epoch[6] Batch [100]\tSpeed: 140.56 samples/sec\tTrain-accuracy=0.980469\n",
      "2016-10-22 18:51:41,172 Epoch[6] Batch [110]\tSpeed: 140.17 samples/sec\tTrain-accuracy=0.978906\n",
      "2016-10-22 18:51:50,312 Epoch[6] Batch [120]\tSpeed: 140.06 samples/sec\tTrain-accuracy=0.978906\n",
      "2016-10-22 18:51:50,314 Epoch[6] Train-accuracy=nan\n",
      "2016-10-22 18:51:50,314 Epoch[6] Time cost=109.974\n",
      "2016-10-22 18:52:23,287 Epoch[6] Validation-accuracy=0.864738\n",
      "2016-10-22 18:52:32,798 Epoch[7] Batch [10]\tSpeed: 139.84 samples/sec\tTrain-accuracy=0.982244\n",
      "2016-10-22 18:52:41,881 Epoch[7] Batch [20]\tSpeed: 140.94 samples/sec\tTrain-accuracy=0.980469\n",
      "2016-10-22 18:52:50,982 Epoch[7] Batch [30]\tSpeed: 140.67 samples/sec\tTrain-accuracy=0.978906\n",
      "2016-10-22 18:53:00,086 Epoch[7] Batch [40]\tSpeed: 140.61 samples/sec\tTrain-accuracy=0.980469\n",
      "2016-10-22 18:53:09,208 Epoch[7] Batch [50]\tSpeed: 140.35 samples/sec\tTrain-accuracy=0.975000\n",
      "2016-10-22 18:53:18,342 Epoch[7] Batch [60]\tSpeed: 140.15 samples/sec\tTrain-accuracy=0.970313\n",
      "2016-10-22 18:53:27,490 Epoch[7] Batch [70]\tSpeed: 139.94 samples/sec\tTrain-accuracy=0.978125\n",
      "2016-10-22 18:53:36,623 Epoch[7] Batch [80]\tSpeed: 140.15 samples/sec\tTrain-accuracy=0.989844\n",
      "2016-10-22 18:53:45,795 Epoch[7] Batch [90]\tSpeed: 139.58 samples/sec\tTrain-accuracy=0.976562\n",
      "2016-10-22 18:53:54,958 Epoch[7] Batch [100]\tSpeed: 139.70 samples/sec\tTrain-accuracy=0.981250\n",
      "2016-10-22 18:54:04,143 Epoch[7] Batch [110]\tSpeed: 139.39 samples/sec\tTrain-accuracy=0.974219\n",
      "2016-10-22 18:54:12,364 Epoch[7] Train-accuracy=0.976562\n",
      "2016-10-22 18:54:12,365 Epoch[7] Time cost=109.077\n",
      "2016-10-22 18:54:45,259 Epoch[7] Validation-accuracy=0.863905\n"
     ]
    }
   ],
   "source": [
    "get_model('http://data.mxnet.io/models/imagenet-11k/resnet-152/resnet-152', 0)\n",
    "sym, arg_params, aux_params = mx.model.load_checkpoint('resnet-152', 0)\n",
    "(new_sym, new_args) = get_fine_tune_model(sym, arg_params, num_classes)\n",
    "fit(new_sym, new_args, aux_params, train, val, batch_size, num_gpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, even for a single data epoch, it reaches 83% validation accuracy. After 8 epoches, the validation accuracy increases to 86.4%. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
