net <- get_lenet()
}
net
args
data_shape
source("./train_model_folkfrom_mxnetexapmle.R")
train_model.fit(args, net, get_iterator(data_shape))
library(im2rec)
install.packages("im2rec")
args = parse_args()
args
args = parse_args(--network lenet)
args = parse_args("--network lenet")
args = parse_args(c("--network", "lenet"))
args$network <- c("lenet")
if (args$network == 'mlp') {
data_shape <- c(784)
net <- get_mlp()
} else {
data_shape <- c(28, 28, 1)
net <- get_lenet()
}
source("./train_model_folkfrom_mxnetexapmle.R")
train_model.fit(args, net, get_iterator(data_shape))
net
args
source("./train_model_folkfrom_mxnetexapmle.R")
train_model.fit(args, net, get_iterator(data_shape))
library(mxnet)
mx.gpu()
install.packages("FNN")
knitr::opts_chunk$set(echo = TRUE)
library(jpeg)
library(imager)
library(FNN)
library(jpeg)
library(imager)
path="D:/PPT/å›¾ç‰‡/"
scl=.3
set=10;id=4
nim <- paste0(path, 'images.jpeg')
im=readJPEG(nim)
str(im)
cim=imresize(as.cimg(im),scale = scl)
str(cim)
str(im)
args = parse_args(c("--network", "lenet"))
args = parse_args()
train           = mx.io.MNISTIter(
image       = paste0("./mnist/train-images-idx3-ubyte"),
label       = paste0("./mnist/train-labels-idx1-ubyte"),
input_shape = c(28, 28, 1),
batch_size  = 64,
shuffle     = TRUE,
flat        = flat)
args
train           = mx.io.MNISTIter(
image       = paste0("./mnist/train-images-idx3-ubyte"),
label       = paste0("./mnist/train-labels-idx1-ubyte"),
input_shape = c(28, 28, 1),
batch_size  = 64,
shuffle     = TRUE,
flat        = F)
train.head(10)
head(train,10)
library(FNN)
library(jpeg)
library(imager)
library(mxnet)
work_path <- c("D:/PPT/å›¾ç‰‡/")
nrow = length(list.files(work_path))
im <- NULL
# i <- 1
PreprocessImage <- function(path,show_img = T){
img <- load.image(path)
short_edge = min(dim(img)[1:2])
yy = (dim(img)[1] - short_edge) / 2
xx = (dim(img)[2] - short_edge) / 2
crop_img = imresize(as.cimg(img[(yy+1) : (yy + short_edge), (xx+1) : (xx + short_edge),,],scale=1))
# convert to numpy.ndarray
sample = as.array(crop_img) * 256
# cat(dim(sample))
# swap axes to make image from (299, 299, 1, 3) to (1, 3, 299, 299)
sample <- permute_axes(sample,"zcxy")
# sub mean
normed_img = sample - 128.
normed_img = normed_img /128.
# print("transformed Image Shape:", dim(normed_img))
return(normed_img)
}
# load img file
for(i in 3){
if(list.files(work_path)[i]){
path = paste0(work_path, list.files(work_path)[i])
img  <- PreprocessImage(path)
}
}
PreprocessImage(path)
path
paste0(work_path, list.files(work_path)[i])
path = paste0(work_path, list.files(work_path)[i])
path
img  <- PreprocessImage(path)
library(mxnet)
get_lenet <- function() {
data <- mx.symbol.Variable('data')
# first conv
conv1 <- mx.symbol.Convolution(data=data, kernel=c(5,5), num_filter=20)
tanh1 <- mx.symbol.Activation(data=conv1, act_type="tanh")
pool1 <- mx.symbol.Pooling(data=tanh1, pool_type="max",
kernel=c(2,2), stride=c(2,2))
# second conv
conv2 <- mx.symbol.Convolution(data=pool1, kernel=c(5,5), num_filter=50)
tanh2 <- mx.symbol.Activation(data=conv2, act_type="tanh")
pool2 <- mx.symbol.Pooling(data=tanh2, pool_type="max",
kernel=c(2,2), stride=c(2,2))
# first fullc
flatten <- mx.symbol.Flatten(data=pool2)
fc1 <- mx.symbol.FullyConnected(data=flatten, num_hidden=500)
# tanh3 <- mx.symbol.Activation(data=fc1, act_type="tanh")
# # second fullc
# fc2 <- mx.symbol.FullyConnected(data=tanh3, num_hidden=10)
# # loss
# lenet <- mx.symbol.SoftmaxOutput(data=fc2, name='softmax')
# lenet
return(fc1)
}
model = mx.model.FeedForward.create(
X                  = img,
# eval.data          = val,
ctx                = devs,
symbol             = get_lenet,
# eval.metric        = mx.metric.accuracy,
num.round          = 10,
learning.rate      = args$lr,
momentum           = 0.9,
wd                 = 0.00001,
batch.end.callback = mx.callback.log.train.metric(50))
conv1 <- mx.symbol.Convolution(data=img, kernel=c(5,5), num_filter=20)
img[1,1,,]
conv1 <- mx.symbol.Convolution(data=img[1,1,,], kernel=c(5,5), num_filter=20)
data = mx.symbol.Variable('data')
conv1 = mx.symbol.Convolution(data=img[1,1,,], kernel=c(5,5), num_filter=20)
model = mx.model.FeedForward.create(
X                  = img[1,1,,],
# eval.data          = val,
ctx                = devs,
symbol             = get_lenet,
# eval.metric        = mx.metric.accuracy,
num.round          = 10,
learning.rate      = args$lr,
momentum           = 0.9,
wd                 = 0.00001,
batch.end.callback = mx.callback.log.train.metric(50))
dim(img)
nchannel = dim(img)[2]
nchannel
1:nchannel
channels
channels = mx.symbol.SliceChannel(simg, num.outputs = nchannel)
nchannel = dim(img)[2]
simg = mx.symbol.Variable("img")
skernel = mx.symbol.Variable("kernel")
channels = mx.symbol.SliceChannel(simg, num.outputs = nchannel)
channels
out = mx.symbol.Concat(*[for(i in 1:nchannel) mx.symbol.Convolution(data=channels[i],weight=skernel
,num.filter = 1,
kernel = (3,3),pad=(1,1),
no.bias = T, stride = (1, 1)
)])
out = mx.symbol.Concat([for(i in 1:nchannel) mx.symbol.Convolution(data=channels[i],weight=skernel
,num.filter = 1,kernel = (3,3), pad=(1,1),
no.bias = T, stride = (2,2)
)])
nchannel
out = mx.symbol.Concat(for(i in 1:nchannel) mx.symbol.Convolution(data=channels[i],weight=skernel
,num.filter = 1,kernel = c(3, 3), pad = c(1, 1),
no.bias = T, stride = c(2, 2)
))
nchannel
conv_r = mx.symbol.Convolution(data=channels[1],weight=skernel
,num.filter = 1,kernel = c(3, 3), pad = c(1, 1),
no.bias = T, stride = c(2, 2)
)
conv_g = mx.symbol.Convolution(data=channels[2],weight=skernel
,num.filter = 1,kernel = c(3, 3), pad = c(1, 1),
no.bias = T, stride = c(2, 2)
)
conv_b = mx.symbol.Convolution(data=channels[3],weight=skernel
,num.filter = 1,kernel = c(3, 3), pad = c(1, 1),
no.bias = T, stride = c(2, 2)
)
channels[1]
channels
str(channels)
dim(channels)
conv_r = mx.symbol.Convolution(data=channels[1],weight=skernel
,num.filter = 1,kernel = c(3, 3), pad = c(1, 1),
no.bias = T, stride = c(2, 2)
)
out = mx.symbol.Concat(list(for(i in 1:nchannel) mx.symbol.Convolution(data=channels[i],weight=skernel
,num.filter = 1,kernel = c(3, 3), pad = c(1, 1),
no.bias = T, stride = c(2, 2)
)),num.args = 3)
mx.symbol.Convolution(data=channels[i]
data=channels[i]
data=channels[i]
conv_r = mx.symbol.Convolution(data = channels[1],weight=skernel
,num.filter = 1,kernel = c(3, 3), pad = c(1, 1),
no.bias = T, stride = c(2, 2))
out = mx.symbol.Concat(list(for(i in 1:nchannel) mx.symbol.Convolution(data=channels[i],weight=skernel
,num.filter = 1,kernel = c(3, 3), pad = c(1, 1),
no.bias = T, stride = c(2, 2)
)),num.args = 3)
channels(1)
channels[1]
channels
channels[[1]]
out = mx.symbol.Concat(list(for(i in 1:nchannel) mx.symbol.Convolution(data=channels[[i]],weight=skernel
,num.filter = 1,kernel = c(3, 3), pad = c(1, 1),
no.bias = T, stride = c(2, 2)
)),num.args = 3)
conv_r = mx.symbol.Convolution(data = channels[[1]], weight = skernel
,num.filter = 1, kernel = c(3, 3), pad = c(1, 1),
no.bias = T, stride = c(2, 2))
conv_g = mx.symbol.Convolution(data=channels[[2]],weight=skernel
,num.filter = 1,kernel = c(3, 3), pad = c(1, 1),
no.bias = T, stride = c(2, 2))
conv_b = mx.symbol.Convolution(data=channels[[3]],weight=skernel
,num.filter = 1,kernel = c(3, 3), pad = c(1, 1),
no.bias = T, stride = c(2, 2))
conv_r
out = mx.symbol.Concat(list(conv_r, conv_g, conv_b),num.args = 3)
library(sparklyr)
sc <- spark_connect(master = "spark://local:7077")
mx.model.FeedForward.create(symbol = get_symbols, X = img, y = NULL)
mx.model.FeedForward.create(symbol = get_symbols, X = img, y = "1")
library(mxnet)
a <- mx.nd.zeros(c(2,3))
a
a <- mx.nd.zeros(c(3,2,3))
a
a <- mx.nd.zeros(c(3,2,3,1))
a
a <- mx.nd.zeros(c(3,2,3,3))
a
b <- mx.nd.ones(c(4,4))
b
mx.nd.array(1:5)
a+1
a
a+1
require(mxnet)
net <- mx.symbol.Variable("data")
net <- mx.symbol.FullyConnected(data=net, name="fc1", num_hidden=128)
net <- mx.symbol.Activation(data=net, name="relu1", act_type="relu")
net <- mx.symbol.FullyConnected(data=net, name="fc2", num_hidden=64)
net <- mx.symbol.SoftmaxOutput(data=net, name="out")
class(net)
arguments(net)
net <- mx.symbol.Variable("img")
net <- mx.symbol.FullyConnected(data=net, name="fc1", num_hidden=128)
net <- mx.symbol.Activation(data=net, name="relu1", act_type="relu")
net <- mx.symbol.FullyConnected(data=net, name="fc2", num_hidden=64)
net <- mx.symbol.SoftmaxOutput(data=net, name="out")
class(net)
arguments(net)
require(mxnet)
net <- mx.symbol.Variable("img")
net <- mx.symbol.FullyConnected(data=net, name="fc1", num_hidden=128)
net <- mx.symbol.FullyConnected(data=net, name="fc2", num_hidden=64)
net <- mx.symbol.SoftmaxOutput(data=net, name="out")
arguments(net)
net <- mx.symbol.Variable("img")
net <- mx.symbol.FullyConnected(data=net, name="fc1", num_hidden=128)
net <- mx.symbol.Convolution(data=net, name="fc1", num_hidden=128)
net <- mx.symbol.Convolution(data=net, name="fc1")
net <- mx.symbol.Convolution(data=net, name="fc1", shape = c(28,28))
net <- mx.symbol.Convolution(data=net, name="fc1", kernel=c(5,5), num_filter=20)
net <- mx.symbol.Variable("img")
net <- mx.symbol.FullyConnected(data=net, name="fc1", num_hidden=128)
net <- mx.symbol.Convolution(data=net, name="fc1", kernel=c(5,5), num_filter=20)
net <- mx.symbol.Activation(data=net, name="relu1", act_type="relu")
net <- mx.symbol.FullyConnected(data=net, name="fc2", num_hidden=64)
net <- mx.symbol.SoftmaxOutput(data=net, name="out")
arguments(net)
net <- mx.symbol.Variable("img")
net <- mx.symbol.FullyConnected(data=net, name="fc1", num_hidden=128)
net <- mx.symbol.Convolution(data=net, name="cv1", kernel=c(5,5), num_filter=20)
net <- mx.symbol.Activation(data=net, name="relu1", act_type="relu")
net <- mx.symbol.FullyConnected(data=net, name="fc2", num_hidden=64)
net <- mx.symbol.SoftmaxOutput(data=net, name="out")
arguments(net)
net <- mx.symbol.FullyConnected(data=net, name="fc1", num_hidden=128,  weight=w)
net <- mx.symbol.Convolution(data=net, name="cv1", kernel=c(5,5), num_filter=20)
net <- mx.symbol.Variable("img")
w <- mx.symbol.Variable("myweight")
net <- mx.symbol.FullyConnected(data=net, name="fc1", num_hidden=128,  weight = w)
net <- mx.symbol.Convolution(data=net, name="cv1", kernel=c(5,5), num_filter=20)
net <- mx.symbol.Activation(data=net, name="relu1", act_type="relu")
net <- mx.symbol.FullyConnected(data=net, name="fc2", num_hidden=64)
net <- mx.symbol.SoftmaxOutput(data=net, name="out")
arguments(net)
net <- mx.symbol.Variable("data")
net <- mx.symbol.FullyConnected(data=net, name="fc1", num_hidden=128)
net2 <- mx.symbol.Variable("data2")
net2 <- mx.symbol.FullyConnected(data=net2, name="net2", num_hidden=128)
composed.net <- mx.apply(net, data=net2, name="compose")
arguments(composed.net)
library(mxnet)
data(BostonHousing, package="mlbench")
train.ind = seq(1, 506, 3)
train.x = data.matrix(BostonHousing[train.ind, -14])
train.y = BostonHousing[train.ind, 14]
test.x = data.matrix(BostonHousing[-train.ind, -14])
test.y = BostonHousing[-train.ind, 14]
data <- mx.symbol.Variable("data")
fc1 <- mx.symbol.FullyConnected(data, num_hidden=1)
lro <- mx.symbol.LinearRegressionOutput(fc1)
mx.set.seed(0)
model <- mx.model.FeedForward.create(
lro, X=train.x, y=train.y,
eval.data=list(data=test.x, label=test.y),
ctx=mx.cpu(), num.round=10, array.batch.size=20,
learning.rate=2e-6, momentum=0.9, eval.metric=mx.metric.rmse)
BostonHousing
dim(BostonHousing)
train.ind
im <- load.image(system.file("extdata/parrots.png", package = "imager"))
im <- load.image(system.file("extdata/parrots.png", package = "imager"))
library(imager)
im <- load.image(system.file("extdata/parrots.png", package = "imager"))
plot(im)
preproc.image <- function(im, mean.image) {
# crop the image
shape <- dim(im)
short.edge <- min(shape[1:2])
xx <- floor((shape[1] - short.edge) / 2)
yy <- floor((shape[2] - short.edge) / 2)
croped <- crop.borders(im, xx, yy)
# resize to 224 x 224, needed by input of the model.
resized <- resize(croped, 224, 224)
# convert to array (x, y, channel)
arr <- as.array(resized) * 255
dim(arr) <- c(224, 224, 3)
# subtract the mean
normed <- arr - mean.img
# Reshape to format needed by mxnet (width, height, channel, num)
dim(normed) <- c(224, 224, 3, 1)
return(normed)
}
normed <- preproc.image(im, mean.img)
normed <- preproc.image(im, 128)
normed <- preproc.image(im, mean.image = 128)
im
shape <- dim(im)
short.edge <- min(shape[1:2])
short.edge
xx <- floor((shape[1] - short.edge) / 2)
yy <- floor((shape[2] - short.edge) / 2)
croped <- crop.borders(im, xx, yy)
dim(croped)
resized <- resize(croped, 224, 224)
arr <- as.array(resized) * 255
dim(arr) <- c(224, 224, 3)
dim(arr)
resized <- resize(croped, 224, 224)
arr <- as.array(resized) * 255
dim(arr)
dim(arr) <- c(224, 224, 3)
dim(arr) <- c(224, 224, 3)
normed <- arr - mean.img
normed <- arr - mean.image
normed <- preproc.image(im, mean.image = 128)
preproc.image <- function(im, mean.image) {
# crop the image
shape <- dim(im)
short.edge <- min(shape[1:2])
xx <- floor((shape[1] - short.edge) / 2)
yy <- floor((shape[2] - short.edge) / 2)
croped <- crop.borders(im, xx, yy)
# dim(croped)
# resize to 224 x 224, needed by input of the model.
resized <- resize(croped, 224, 224)
# convert to array (x, y, channel)
arr <- as.array(resized) * 255
dim(arr)
dim(arr) <- c(224, 224, 3)
# subtract the mean
normed <- arr - mean.image
# Reshape to format needed by mxnet (width, height, channel, num)
dim(normed) <- c(224, 224, 3, 1)
return(normed)
}
normed <- preproc.image(im, mean.image = 128)
plot(normed)
library(mxnet)
model <- mx.model.load("./inception-bn", iteration = 39)
synsets <- readLines("./inception-bn/synset.txt")
print(paste0("Predicted Top-class: ", synsets[[max.idx]]))
max.idx =2
print(paste0("Predicted Top-class: ", synsets[[max.idx]]))
synsets
model <- mx.model.load("./inception-bn", iteration = 39)
model <- mx.model.load("./inception-bn/Inception_BN-0039.params", iteration = 39)
model <- mx.model.load("./inception-bn/Inception_BN-0039.params", iteration = 39)
mean.img <- as.array(mx.nd.load("Inception/mean_224.nd")[["mean_img"]])
mean.img <- as.array(mx.nd.load("./inception-bn/mean_224.nd")[["mean_img"]])
graph.viz(model$symbol$as.json())
# define the network
data <- mx.symbol.Variable("data")
fc1 <- mx.symbol.FullyConnected(data, num_hidden=1)
cn1 <- mx.symbol.Convolution(fc1, kernel=c(2,2))
lro <- mx.symbol.LinearRegressionOutput(cn1)
# train model
mx.set.seed(0)
model <- mx.model.FeedForward.create(
lro, X=train.x, y=train.y,
eval.data=list(data=test.x, label=test.y),
ctx=mx.cpu(), num.round=10, array.batch.size=20,
learning.rate=2e-6, momentum=0.9, eval.metric=mx.metric.rmse)
graph.viz(model$symbol$as.json())
data <- mx.symbol.Variable("data")
fc1 <- mx.symbol.FullyConnected(data, num_hidden=1)
cn1 <- mx.symbol.Convolution(data=fc1, kernel=c(2,2))
cn1 <- mx.symbol.Convolution(data=fc1, kernel=c(2,2), num_filter = 50)
lro <- mx.symbol.LinearRegressionOutput(cn1)
mx.set.seed(0)
model <- mx.model.FeedForward.create(
lro, X=train.x, y=train.y,
eval.data=list(data=test.x, label=test.y),
ctx=mx.cpu(), num.round=10, array.batch.size=20,
learning.rate=2e-6, momentum=0.9, eval.metric=mx.metric.rmse)
lro <- mx.symbol.LinearRegressionOutput(fc1)
mx.set.seed(0)
model <- mx.model.FeedForward.create(
lro, X=train.x, y=train.y,
eval.data=list(data=test.x, label=test.y),
ctx=mx.cpu(), num.round=10, array.batch.size=20,
learning.rate=2e-6, momentum=0.9, eval.metric=mx.metric.rmse)
graph.viz(model$symbol$as.json())
model <- mx.model.load("./inception-bn/Inception_BN-0039.params", iteration = 39)
model$arg.params$fullyconnected2_weight
model$arg.params$fullyconnected2_bias
model$aux.params
model$symbol$outputs
model$symbol$arguments
model$symbol$apply
str(synsets)
model <- mx.model.load("./inception-bn/", iteration = 39)
model <- mx.model.load("./inception-bn", iteration = 39)
model <- mx.model.load("./inception-bn", iteration = 39)
model <- mx.model.load("./inception-bn/Inception_BN-symbol.json", iteration = 39)
model <- mx.model.load("./inception-bn/Inception_BN-0039.params", iteration = 39)
install.packages("mxnet")
install.packages("mxnet")
install.packages("mxnet")
install.packages("mxnet")
install.packages("mxnet")
install.packages("mxnet")
model <- mx.model.load("./inception-bn", iteration = 39)
library(mxnet)
library(imager)
model <- mx.model.load("./inception-bn", iteration = 39)
model <- mx.model.load("./inception-bn", iteration = 39)
mx.model.save(model, './nn_lr_model')
mx.model.save(model, './')
graph.viz(model$symbol$as.json())
library(mxnet)
# data prepare
data(BostonHousing, package="mlbench")
train.ind = seq(1, 506, 3)
train.x = data.matrix(BostonHousing[train.ind, -14])
train.y = BostonHousing[train.ind, 14]
test.x = data.matrix(BostonHousing[-train.ind, -14])
test.y = BostonHousing[-train.ind, 14]
# define the network
data <- mx.symbol.Variable("data")
fc1 <- mx.symbol.FullyConnected(data, num_hidden=1)
# the data should be 4D in batch-num_filter-y-x
# cn1 <- mx.symbol.Convolution(data=fc1, kernel=c(2,2), num_filter = 50)
lro <- mx.symbol.LinearRegressionOutput(fc1)
# train model
mx.set.seed(0)
model <- mx.model.FeedForward.create(
lro, X=train.x, y=train.y,
eval.data=list(data=test.x, label=test.y),
ctx=mx.cpu(), num.round=10, array.batch.size=20,
learning.rate=2e-6, momentum=0.9, eval.metric=mx.metric.rmse)
# see the computation graph
graph.viz(model$symbol$as.json())
mx.model.save(model, './nn_lr')
mx.model.save(model, './nn_lr', iteration = 10)
mx.model.load('./trainedmodel/nn_lr-symbol.json')
install.packages("D:/gitcode/mxnet/mxnet_0.7.tar.gz", repos = NULL, type = "source")
library(mxnet)
library(mxnet)
library(imager)
model <- mx.model.load("./inception-bn/Inception-BN", iteration = 126)
graph.viz(model$symbol$as.json())
mean.img <- as.array(mx.nd.load("./inception-bn/mean_224.nd")[["mean_img"]])
summary(mean.img)
graph.viz(model$symbol$as.json())
model$symbol$get.internals
model$symbol$get.internals()
model
interals <- model$symbol$get.internals()
internals <- model$symbol$get.internals()
internals$get.output()
internals$outputs()
internals$outputs()
internals$outputs
